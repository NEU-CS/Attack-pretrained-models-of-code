INFO 02-28 18:47:26 llm_engine.py:72] Initializing an LLM engine with config: model='deepseek-ai/deepseek-coder-6.7b-base', tokenizer='deepseek-ai/deepseek-coder-6.7b-base', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, seed=0)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
INFO 02-28 18:47:29 weight_utils.py:164] Using model weights format ['*.bin']
INFO 02-28 18:47:37 llm_engine.py:322] # GPU blocks: 553, # CPU blocks: 512
INFO 02-28 18:47:38 model_runner.py:632] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 02-28 18:47:38 model_runner.py:636] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 02-28 18:47:43 model_runner.py:698] Graph capturing finished in 5 secs.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/home/ljc/miniconda3/envs/adv/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Some weights of the model checkpoint at microsoft/codebert-base-mlm were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 15033.35it/s]
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 2214.52it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 1000 examples [00:00, 278321.43 examples/s]
0it [00:00, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
INFO 02-28 18:47:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:47:52 llm_engine.py:878] Avg prompt throughput: 21.9 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! serialize => store prob: 1.0 => 0.6458342165986974
INFO 02-28 18:47:57 llm_engine.py:878] Avg prompt throughput: 42.7 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
1it [00:13, 13.49s/it]ACC! out => os prob: 0.6458342165986974 => 0.4785005519047641
Example index 0
Example time cost:  0.22 min
ALL examples time cost:  0.22 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.4785005519047641
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  0




INFO 02-28 18:48:02 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:07 llm_engine.py:878] Avg prompt throughput: 30.4 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:12 llm_engine.py:878] Avg prompt throughput: 29.7 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:17 llm_engine.py:878] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:22 llm_engine.py:878] Avg prompt throughput: 32.7 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:27 llm_engine.py:878] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:32 llm_engine.py:878] Avg prompt throughput: 42.4 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:42 llm_engine.py:878] Avg prompt throughput: 22.4 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:47 llm_engine.py:878] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
ACC! src => shuffle prob: 0.6685731536097567 => 0.4798483482022369
INFO 02-28 18:48:52 llm_engine.py:878] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:48:57 llm_engine.py:878] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:02 llm_engine.py:878] Avg prompt throughput: 29.1 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
NOACC! addAll => process prob: 0.4798483482022369 => 0.6660169865707698
INFO 02-28 18:49:07 llm_engine.py:878] Avg prompt throughput: 31.7 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:12 llm_engine.py:878] Avg prompt throughput: 32.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:17 llm_engine.py:878] Avg prompt throughput: 34.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:22 llm_engine.py:878] Avg prompt throughput: 36.1 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:27 llm_engine.py:878] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:32 llm_engine.py:878] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:42 llm_engine.py:878] Avg prompt throughput: 21.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:47 llm_engine.py:878] Avg prompt throughput: 22.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:52 llm_engine.py:878] Avg prompt throughput: 23.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:49:57 llm_engine.py:878] Avg prompt throughput: 24.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
2it [02:13, 76.35s/it]NOACC! srcDirIdx => process prob: 0.4798483482022369 => 0.5112170430071283
Example index 1
Example time cost:  2.01 min
ALL examples time cost:  2.23 min
Origin CodeBLEU: 0.6685731536097567
Attacked CodeBLEU: 0.4798483482022369
Greedy_query_times:  46
Ga_query_times:  0
ALL query times:  18




INFO 02-28 18:50:02 llm_engine.py:878] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:07 llm_engine.py:878] Avg prompt throughput: 19.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:12 llm_engine.py:878] Avg prompt throughput: 45.4 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! writeByte => add prob: 0.14281416546388329 => 0.11907155921026653
INFO 02-28 18:50:17 llm_engine.py:878] Avg prompt throughput: 34.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:22 llm_engine.py:878] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:27 llm_engine.py:878] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:32 llm_engine.py:878] Avg prompt throughput: 43.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:37 llm_engine.py:878] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:42 llm_engine.py:878] Avg prompt throughput: 35.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! upto => this prob: 0.11907155921026653 => 0.11045086955509412
INFO 02-28 18:50:47 llm_engine.py:878] Avg prompt throughput: 36.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:52 llm_engine.py:878] Avg prompt throughput: 34.8 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:50:57 llm_engine.py:878] Avg prompt throughput: 44.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! currentBlock => buf prob: 0.11045086955509412 => 0.0932094902447493
INFO 02-28 18:51:02 llm_engine.py:878] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:07 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:12 llm_engine.py:878] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
3it [03:26, 74.44s/it]4it [03:28, 46.04s/it]ACC! b => v prob: 0.0932094902447493 => 0.09286181916139756
Example index 2
Example time cost:  1.2 min
ALL examples time cost:  3.43 min
Origin CodeBLEU: 0.14281416546388329
Attacked CodeBLEU: 0.09286181916139756
Greedy_query_times:  55
Ga_query_times:  0
ALL query times:  64




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getObjectId => Id prob: 0.75 => 0.3954739241427606
Example index 3
Example time cost:  0.04 min
ALL examples time cost:  3.48 min
Origin CodeBLEU: 0.75
Attacked CodeBLEU: 0.3954739241427606
Greedy_query_times:  6
Ga_query_times:  0
ALL query times:  119




INFO 02-28 18:51:17 llm_engine.py:878] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:22 llm_engine.py:878] Avg prompt throughput: 14.1 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:27 llm_engine.py:878] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! deleteDomainEntry => update prob: 1.0 => 0.9017295359335316
INFO 02-28 18:51:32 llm_engine.py:878] Avg prompt throughput: 16.8 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:37 llm_engine.py:878] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:42 llm_engine.py:878] Avg prompt throughput: 28.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
5it [04:02, 41.54s/it]ACC! request => parent prob: 0.9017295359335316 => 0.1478631136068262
Example index 4
Example time cost:  0.56 min
ALL examples time cost:  4.03 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  125




INFO 02-28 18:51:52 llm_engine.py:878] Avg prompt throughput: 36.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:51:57 llm_engine.py:878] Avg prompt throughput: 34.8 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
6it [04:13, 31.43s/it]ACC! ramBytesUsed => length prob: 0.4040976380051231 => 0.35676134739263676
Example index 5
Example time cost:  0.2 min
ALL examples time cost:  4.23 min
Origin CodeBLEU: 0.4040976380051231
Attacked CodeBLEU: 0.35676134739263676
Greedy_query_times:  9
Ga_query_times:  0
ALL query times:  145




INFO 02-28 18:52:02 llm_engine.py:878] Avg prompt throughput: 38.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:07 llm_engine.py:878] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:12 llm_engine.py:878] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:17 llm_engine.py:878] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:22 llm_engine.py:878] Avg prompt throughput: 31.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:27 llm_engine.py:878] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! msgB => buffer prob: 0.6600977356922811 => 0.4482371699602694
INFO 02-28 18:52:32 llm_engine.py:878] Avg prompt throughput: 31.7 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:37 llm_engine.py:878] Avg prompt throughput: 42.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:42 llm_engine.py:878] Avg prompt throughput: 34.7 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! raw => get prob: 0.4482371699602694 => 0.28810854352196524
INFO 02-28 18:52:47 llm_engine.py:878] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
7it [05:02, 36.92s/it]ACC! getFullMessage => get prob: 0.28810854352196524 => 0.24355003825847577
Example index 6
Example time cost:  0.8 min
ALL examples time cost:  5.04 min
Origin CodeBLEU: 0.6600977356922811
Attacked CodeBLEU: 0.24355003825847577
Greedy_query_times:  33
Ga_query_times:  0
ALL query times:  154




INFO 02-28 18:52:52 llm_engine.py:878] Avg prompt throughput: 35.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:52:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:07 llm_engine.py:878] Avg prompt throughput: 35.5 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:18 llm_engine.py:878] Avg prompt throughput: 28.8 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:23 llm_engine.py:878] Avg prompt throughput: 36.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
ACC! bb => synchronized prob: 0.1956033194547314 => 0.18003839539775252
INFO 02-28 18:53:33 llm_engine.py:878] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
8it [05:47, 39.58s/it]NOACC! this => init prob: 0.18003839539775252 => 0.1956033194547314
Example index 7
Example time cost:  0.75 min
ALL examples time cost:  5.79 min
Origin CodeBLEU: 0.1956033194547314
Attacked CodeBLEU: 0.18003839539775252
Greedy_query_times:  13
Ga_query_times:  0
ALL query times:  187




INFO 02-28 18:53:38 llm_engine.py:878] Avg prompt throughput: 20.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:43 llm_engine.py:878] Avg prompt throughput: 34.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:48 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:53 llm_engine.py:878] Avg prompt throughput: 23.2 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:53:58 llm_engine.py:878] Avg prompt throughput: 33.8 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:03 llm_engine.py:878] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:08 llm_engine.py:878] Avg prompt throughput: 23.4 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:13 llm_engine.py:878] Avg prompt throughput: 33.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:18 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:23 llm_engine.py:878] Avg prompt throughput: 22.7 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! slice => blocks prob: 0.8641327577154697 => 0.6466091550861952
INFO 02-28 18:54:28 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:33 llm_engine.py:878] Avg prompt throughput: 36.8 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:38 llm_engine.py:878] Avg prompt throughput: 21.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:43 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:48 llm_engine.py:878] Avg prompt throughput: 35.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:54:53 llm_engine.py:878] Avg prompt throughput: 20.5 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! address => 0 prob: 0.6466091550861952 => 0.41438386221630286
INFO 02-28 18:54:58 llm_engine.py:878] Avg prompt throughput: 29.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:03 llm_engine.py:878] Avg prompt throughput: 33.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:08 llm_engine.py:878] Avg prompt throughput: 19.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:13 llm_engine.py:878] Avg prompt throughput: 29.5 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:18 llm_engine.py:878] Avg prompt throughput: 33.6 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:23 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:28 llm_engine.py:878] Avg prompt throughput: 23.3 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:33 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! upto => buffers prob: 0.41438386221630286 => 0.36301883529748946
INFO 02-28 18:55:38 llm_engine.py:878] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:43 llm_engine.py:878] Avg prompt throughput: 21.5 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:48 llm_engine.py:878] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:53 llm_engine.py:878] Avg prompt throughput: 35.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:55:58 llm_engine.py:878] Avg prompt throughput: 20.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:56:03 llm_engine.py:878] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:56:08 llm_engine.py:878] Avg prompt throughput: 35.2 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:56:13 llm_engine.py:878] Avg prompt throughput: 20.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
NOACC! offset0 => block prob: 0.36301883529748946 => 0.36301883529748946
INFO 02-28 18:56:18 llm_engine.py:878] Avg prompt throughput: 30.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:56:23 llm_engine.py:878] Avg prompt throughput: 33.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
9it [08:39, 81.01s/it]ACC! init => free prob: 0.36301883529748946 => 0.30900881965910315
Example index 8
Example time cost:  2.87 min
ALL examples time cost:  8.66 min
Origin CodeBLEU: 0.8641327577154697
Attacked CodeBLEU: 0.30900881965910315
Greedy_query_times:  92
Ga_query_times:  0
ALL query times:  200




INFO 02-28 18:56:28 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! setPath => path prob: 1.0 => 0.7521747284136531
INFO 02-28 18:56:33 llm_engine.py:878] Avg prompt throughput: 33.1 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
10it [08:50, 59.45s/it]ACC! path => paths prob: 0.7521747284136531 => 0.4974123126148854
Example index 9
Example time cost:  0.19 min
ALL examples time cost:  8.84 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.4974123126148854
Greedy_query_times:  15
Ga_query_times:  0
ALL query times:  292




INFO 02-28 18:56:38 llm_engine.py:878] Avg prompt throughput: 31.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:56:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:56:48 llm_engine.py:878] Avg prompt throughput: 10.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:56:53 llm_engine.py:878] Avg prompt throughput: 10.5 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! listIngestions => get prob: 1.0 => 0.9017295359335316
INFO 02-28 18:56:58 llm_engine.py:878] Avg prompt throughput: 16.2 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:57:03 llm_engine.py:878] Avg prompt throughput: 19.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 18:57:08 llm_engine.py:878] Avg prompt throughput: 27.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
11it [09:25, 51.96s/it]ACC! request => req prob: 0.9017295359335316 => 0.11101779823773752
Example index 10
Example time cost:  0.58 min
ALL examples time cost:  9.43 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  307




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 18:57:13 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 18:57:18 llm_engine.py:878] Avg prompt throughput: 27.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! stream => input prob: 0.6351270220691088 => 0.31302664548075765
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 18:57:23 llm_engine.py:878] Avg prompt throughput: 35.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
12it [09:39, 40.31s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! lexState => ch prob: 0.31302664548075765 => 0.08510067234934053
Example index 11
Example time cost:  0.23 min
ALL examples time cost:  9.66 min
Origin CodeBLEU: 0.6351270220691088
Attacked CodeBLEU: 0.08510067234934053
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  326




INFO 02-28 18:57:28 llm_engine.py:878] Avg prompt throughput: 31.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:57:33 llm_engine.py:878] Avg prompt throughput: 16.1 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:57:38 llm_engine.py:878] Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! getShardIterator => get prob: 1.0 => 0.9017295359335316
INFO 02-28 18:57:43 llm_engine.py:878] Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:57:48 llm_engine.py:878] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:57:53 llm_engine.py:878] Avg prompt throughput: 20.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
13it [10:11, 37.75s/it]ACC! request => resource prob: 0.9017295359335316 => 0.11101779823773752
Example index 12
Example time cost:  0.53 min
ALL examples time cost:  10.19 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  343




INFO 02-28 18:57:58 llm_engine.py:878] Avg prompt throughput: 28.8 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
14it [10:12, 26.72s/it]Example index 13
Example time cost:  0.02 min
ALL examples time cost:  10.21 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 1.0
Greedy_query_times:  1
Ga_query_times:  0
ALL query times:  362




INFO 02-28 18:58:03 llm_engine.py:878] Avg prompt throughput: 32.6 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:08 llm_engine.py:878] Avg prompt throughput: 40.7 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
15it [10:22, 21.80s/it]16it [10:25, 16.07s/it]ACC! ready => has prob: 0.8749321403029341 => 0.7639516991548829
Example index 14
Example time cost:  0.17 min
ALL examples time cost:  10.38 min
Origin CodeBLEU: 0.8749321403029341
Attacked CodeBLEU: 0.7639516991548829
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  363




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getOptRecord => get prob: 0.2860223939199411 => 0.1874318589350426
Example index 15
Example time cost:  0.05 min
ALL examples time cost:  10.43 min
Origin CodeBLEU: 0.2860223939199411
Attacked CodeBLEU: 0.1874318589350426
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  370




INFO 02-28 18:58:13 llm_engine.py:878] Avg prompt throughput: 34.4 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:23 llm_engine.py:878] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:28 llm_engine.py:878] Avg prompt throughput: 47.8 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:38 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:48 llm_engine.py:878] Avg prompt throughput: 28.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:53 llm_engine.py:878] Avg prompt throughput: 35.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 18:58:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:03 llm_engine.py:878] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:08 llm_engine.py:878] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:18 llm_engine.py:878] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:23 llm_engine.py:878] Avg prompt throughput: 33.5 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:33 llm_engine.py:878] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:38 llm_engine.py:878] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:43 llm_engine.py:878] Avg prompt throughput: 42.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:53 llm_engine.py:878] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 18:59:59 llm_engine.py:878] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! copylen => pos prob: 0.8517949341582096 => 0.6793374396873793
INFO 02-28 19:00:04 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:09 llm_engine.py:878] Avg prompt throughput: 30.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:14 llm_engine.py:878] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:24 llm_engine.py:878] Avg prompt throughput: 28.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:29 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:39 llm_engine.py:878] Avg prompt throughput: 28.4 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:44 llm_engine.py:878] Avg prompt throughput: 42.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:54 llm_engine.py:878] Avg prompt throughput: 31.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:00:59 llm_engine.py:878] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:04 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:09 llm_engine.py:878] Avg prompt throughput: 29.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:14 llm_engine.py:878] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:24 llm_engine.py:878] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:29 llm_engine.py:878] Avg prompt throughput: 35.6 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:39 llm_engine.py:878] Avg prompt throughput: 27.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
ACC! pos => 1 prob: 0.6793374396873793 => 0.5022802989711924
INFO 02-28 19:01:44 llm_engine.py:878] Avg prompt throughput: 36.8 tokens/s, Avg generation throughput: 39.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:54 llm_engine.py:878] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:01:59 llm_engine.py:878] Avg prompt throughput: 31.9 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:04 llm_engine.py:878] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:14 llm_engine.py:878] Avg prompt throughput: 29.1 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:19 llm_engine.py:878] Avg prompt throughput: 36.1 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:24 llm_engine.py:878] Avg prompt throughput: 52.9 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:34 llm_engine.py:878] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:39 llm_engine.py:878] Avg prompt throughput: 32.4 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:44 llm_engine.py:878] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:02:54 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
ACC! length => input prob: 0.5022802989711924 => 0.3987734314244096
INFO 02-28 19:02:59 llm_engine.py:878] Avg prompt throughput: 32.7 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:04 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:09 llm_engine.py:878] Avg prompt throughput: 48.3 tokens/s, Avg generation throughput: 42.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:14 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:19 llm_engine.py:878] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:24 llm_engine.py:878] Avg prompt throughput: 36.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:29 llm_engine.py:878] Avg prompt throughput: 44.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! buffer => buffer prob: 0.3987734314244096 => 0.31114967407397237
INFO 02-28 19:03:34 llm_engine.py:878] Avg prompt throughput: 46.5 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:39 llm_engine.py:878] Avg prompt throughput: 48.7 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:44 llm_engine.py:878] Avg prompt throughput: 49.1 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:49 llm_engine.py:878] Avg prompt throughput: 51.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:54 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:03:59 llm_engine.py:878] Avg prompt throughput: 32.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:04 llm_engine.py:878] Avg prompt throughput: 31.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:09 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:14 llm_engine.py:878] Avg prompt throughput: 33.1 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:19 llm_engine.py:878] Avg prompt throughput: 35.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! offset => write prob: 0.31114967407397237 => 0.25204297640255624
INFO 02-28 19:04:24 llm_engine.py:878] Avg prompt throughput: 35.4 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:29 llm_engine.py:878] Avg prompt throughput: 36.3 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:34 llm_engine.py:878] Avg prompt throughput: 45.7 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:44 llm_engine.py:878] Avg prompt throughput: 31.8 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:49 llm_engine.py:878] Avg prompt throughput: 42.4 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:54 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:04:59 llm_engine.py:878] Avg prompt throughput: 31.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:04 llm_engine.py:878] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:14 llm_engine.py:878] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:19 llm_engine.py:878] Avg prompt throughput: 34.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:24 llm_engine.py:878] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:29 llm_engine.py:878] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:39 llm_engine.py:878] Avg prompt throughput: 30.5 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:44 llm_engine.py:878] Avg prompt throughput: 34.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! i => index prob: 0.25204297640255624 => 0.24191544094850204
INFO 02-28 19:05:49 llm_engine.py:878] Avg prompt throughput: 33.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:05:54 llm_engine.py:878] Avg prompt throughput: 36.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
17it [18:11, 151.33s/it]NOACC! read => write prob: 0.24191544094850204 => 0.24191544094850204
Example index 16
Example time cost:  7.76 min
ALL examples time cost:  18.19 min
Origin CodeBLEU: 0.8517949341582096
Attacked CodeBLEU: 0.24191544094850204
Greedy_query_times:  162
Ga_query_times:  0
ALL query times:  377




INFO 02-28 19:05:59 llm_engine.py:878] Avg prompt throughput: 45.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:06:04 llm_engine.py:878] Avg prompt throughput: 46.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
18it [18:18, 107.93s/it]ACC! sentenceOp => open prob: 1.0 => 0.5649787723081164
Example index 17
Example time cost:  0.12 min
ALL examples time cost:  18.31 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5649787723081164
Greedy_query_times:  9
Ga_query_times:  0
ALL query times:  539




INFO 02-28 19:06:09 llm_engine.py:878] Avg prompt throughput: 46.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! str => line prob: 0.7748138999744721 => 0.5049344856993273
INFO 02-28 19:06:14 llm_engine.py:878] Avg prompt throughput: 52.1 tokens/s, Avg generation throughput: 39.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
19it [18:30, 79.25s/it] ACC! print => write prob: 0.5049344856993273 => 0.326283462863863
Example index 18
Example time cost:  0.21 min
ALL examples time cost:  18.51 min
Origin CodeBLEU: 0.7748138999744721
Attacked CodeBLEU: 0.326283462863863
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  548




INFO 02-28 19:06:19 llm_engine.py:878] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:06:24 llm_engine.py:878] Avg prompt throughput: 35.4 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! functionName => cause prob: 0.5854868942093372 => 0.43476283527604564
INFO 02-28 19:06:30 llm_engine.py:878] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:06:35 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
20it [18:51, 61.67s/it]ACC! cause => null prob: 0.43476283527604564 => 0.3269191218394943
Example index 19
Example time cost:  0.34 min
ALL examples time cost:  18.86 min
Origin CodeBLEU: 0.5854868942093372
Attacked CodeBLEU: 0.3269191218394943
Greedy_query_times:  23
Ga_query_times:  0
ALL query times:  568




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 19:06:40 llm_engine.py:878] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
21it [18:54, 44.05s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! next => peek prob: 0.75 => 0.29276962129420897
Example index 20
Example time cost:  0.05 min
ALL examples time cost:  18.91 min
Origin CodeBLEU: 0.75
Attacked CodeBLEU: 0.29276962129420897
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  591




INFO 02-28 19:06:45 llm_engine.py:878] Avg prompt throughput: 15.7 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:06:50 llm_engine.py:878] Avg prompt throughput: 108.7 tokens/s, Avg generation throughput: 38.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:06:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:07:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
ACC! readBytes => fill prob: 0.8736292586610104 => 0.745612604743438
INFO 02-28 19:08:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:08:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:09:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:10:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
ACC! len => 0 prob: 0.745612604743438 => 0.5526683533753678
INFO 02-28 19:11:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:11:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:12:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:13:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:14:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
ACC! bufferPosition => full prob: 0.5526683533753678 => 0.46112356523100173
INFO 02-28 19:15:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:15:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:16:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:17:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
ACC! bufferLength => off prob: 0.46112356523100173 => 0.3714437576142474
INFO 02-28 19:18:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:18:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:19:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:20:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
ACC! available => 0 prob: 0.3714437576142474 => 0.19781658500617721
INFO 02-28 19:21:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:21:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:02 llm_engine.py:878] Avg prompt throughput: 58.6 tokens/s, Avg generation throughput: 39.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:22:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
NOACC! offset => output prob: 0.19781658500617721 => 0.19781658500617721
INFO 02-28 19:23:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:32 llm_engine.py:878] Avg prompt throughput: 48.0 tokens/s, Avg generation throughput: 39.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:23:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:07 llm_engine.py:878] Avg prompt throughput: 81.5 tokens/s, Avg generation throughput: 39.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
NOACC! b => fill prob: 0.19781658500617721 => 0.19781658500617721
INFO 02-28 19:24:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:42 llm_engine.py:878] Avg prompt throughput: 54.6 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:24:57 llm_engine.py:878] Avg prompt throughput: 63.0 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:02 llm_engine.py:878] Avg prompt throughput: 70.5 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:12 llm_engine.py:878] Avg prompt throughput: 70.2 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:22 llm_engine.py:878] Avg prompt throughput: 62.8 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:25:58 llm_engine.py:878] Avg prompt throughput: 48.5 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:38 llm_engine.py:878] Avg prompt throughput: 63.2 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:26:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:03 llm_engine.py:878] Avg prompt throughput: 51.2 tokens/s, Avg generation throughput: 39.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
ACC! after => capacity prob: 0.19781658500617721 => 0.10676068168727645
INFO 02-28 19:27:13 llm_engine.py:878] Avg prompt throughput: 50.4 tokens/s, Avg generation throughput: 39.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:27:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:28:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:29:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
NOACC! useBuffer => filled prob: 0.10676068168727645 => 0.20969865863401127
INFO 02-28 19:30:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:23 llm_engine.py:878] Avg prompt throughput: 65.8 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:48 llm_engine.py:878] Avg prompt throughput: 64.4 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:30:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:03 llm_engine.py:878] Avg prompt throughput: 71.7 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:18 llm_engine.py:878] Avg prompt throughput: 52.3 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:31:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:14 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:24 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:44 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
22it [45:00, 500.68s/it]NOACC! bufferStart => 1 prob: 0.10676068168727645 => 0.1785487469512708
Example index 21
Example time cost:  26.09 min
ALL examples time cost:  45.0 min
Origin CodeBLEU: 0.8736292586610104
Attacked CodeBLEU: 0.10676068168727645
Greedy_query_times:  284
Ga_query_times:  0
ALL query times:  598




INFO 02-28 19:32:49 llm_engine.py:878] Avg prompt throughput: 18.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:54 llm_engine.py:878] Avg prompt throughput: 12.5 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:32:59 llm_engine.py:878] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! tagQueue => create prob: 1.0 => 0.6641350368051335
INFO 02-28 19:33:04 llm_engine.py:878] Avg prompt throughput: 13.5 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:09 llm_engine.py:878] Avg prompt throughput: 14.2 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:14 llm_engine.py:878] Avg prompt throughput: 15.1 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:19 llm_engine.py:878] Avg prompt throughput: 17.2 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:24 llm_engine.py:878] Avg prompt throughput: 19.1 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
23it [45:38, 362.04s/it]24it [45:41, 254.39s/it]ACC! request => query prob: 0.6641350368051335 => 0.6223676901056054
Example index 22
Example time cost:  0.64 min
ALL examples time cost:  45.64 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.6223676901056054
Greedy_query_times:  22
Ga_query_times:  0
ALL query times:  882




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
NOACC! remove => unused prob: 0.12794720103425145 => 0.12794720103425145
Example index 23
Example time cost:  0.05 min
ALL examples time cost:  45.7 min
Origin CodeBLEU: 0.12794720103425145
Attacked CodeBLEU: 0.12794720103425145
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  904




INFO 02-28 19:33:29 llm_engine.py:878] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:44 llm_engine.py:878] Avg prompt throughput: 11.7 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:49 llm_engine.py:878] Avg prompt throughput: 10.5 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! modifyCacheSubnetGroup => modify prob: 1.0 => 0.9017295359335316
INFO 02-28 19:33:54 llm_engine.py:878] Avg prompt throughput: 19.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:33:59 llm_engine.py:878] Avg prompt throughput: 21.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:04 llm_engine.py:878] Avg prompt throughput: 18.5 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:09 llm_engine.py:878] Avg prompt throughput: 13.8 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:14 llm_engine.py:878] Avg prompt throughput: 11.4 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
25it [46:30, 192.50s/it]ACC! request => update prob: 0.9017295359335316 => 0.1478631136068262
Example index 24
Example time cost:  0.8 min
ALL examples time cost:  46.5 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  911




INFO 02-28 19:34:19 llm_engine.py:878] Avg prompt throughput: 9.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:24 llm_engine.py:878] Avg prompt throughput: 22.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:29 llm_engine.py:878] Avg prompt throughput: 22.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:34 llm_engine.py:878] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:39 llm_engine.py:878] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:44 llm_engine.py:878] Avg prompt throughput: 34.8 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:49 llm_engine.py:878] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:54 llm_engine.py:878] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:34:59 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! params => param prob: 0.37959872056661303 => 0.23259632887017312
INFO 02-28 19:35:04 llm_engine.py:878] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:09 llm_engine.py:878] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:14 llm_engine.py:878] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! setParams => initialize prob: 0.23259632887017312 => 0.1913912767807774
INFO 02-28 19:35:19 llm_engine.py:878] Avg prompt throughput: 22.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:24 llm_engine.py:878] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:29 llm_engine.py:878] Avg prompt throughput: 22.9 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:34 llm_engine.py:878] Avg prompt throughput: 20.6 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:39 llm_engine.py:878] Avg prompt throughput: 19.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:44 llm_engine.py:878] Avg prompt throughput: 20.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:49 llm_engine.py:878] Avg prompt throughput: 19.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:54 llm_engine.py:878] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:35:59 llm_engine.py:878] Avg prompt throughput: 31.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:04 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:09 llm_engine.py:878] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:14 llm_engine.py:878] Avg prompt throughput: 32.5 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:24 llm_engine.py:878] Avg prompt throughput: 19.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:29 llm_engine.py:878] Avg prompt throughput: 19.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
NOACC! st => params prob: 0.1913912767807774 => 0.1913912767807774
INFO 02-28 19:36:34 llm_engine.py:878] Avg prompt throughput: 19.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:39 llm_engine.py:878] Avg prompt throughput: 19.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:44 llm_engine.py:878] Avg prompt throughput: 19.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:49 llm_engine.py:878] Avg prompt throughput: 21.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:54 llm_engine.py:878] Avg prompt throughput: 21.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:36:59 llm_engine.py:878] Avg prompt throughput: 20.9 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:04 llm_engine.py:878] Avg prompt throughput: 20.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
NOACC! language => parse prob: 0.1913912767807774 => 0.1913912767807774
INFO 02-28 19:37:09 llm_engine.py:878] Avg prompt throughput: 20.4 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:14 llm_engine.py:878] Avg prompt throughput: 20.5 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:19 llm_engine.py:878] Avg prompt throughput: 21.1 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:24 llm_engine.py:878] Avg prompt throughput: 20.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:29 llm_engine.py:878] Avg prompt throughput: 21.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:34 llm_engine.py:878] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:44 llm_engine.py:878] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:54 llm_engine.py:878] Avg prompt throughput: 23.4 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:37:59 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
NOACC! country => params prob: 0.1913912767807774 => 0.1913912767807774
INFO 02-28 19:38:04 llm_engine.py:878] Avg prompt throughput: 23.5 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:09 llm_engine.py:878] Avg prompt throughput: 22.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:14 llm_engine.py:878] Avg prompt throughput: 24.4 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:19 llm_engine.py:878] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:24 llm_engine.py:878] Avg prompt throughput: 22.4 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:29 llm_engine.py:878] Avg prompt throughput: 21.7 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:35 llm_engine.py:878] Avg prompt throughput: 21.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:40 llm_engine.py:878] Avg prompt throughput: 20.2 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:45 llm_engine.py:878] Avg prompt throughput: 19.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:50 llm_engine.py:878] Avg prompt throughput: 21.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:38:55 llm_engine.py:878] Avg prompt throughput: 21.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:00 llm_engine.py:878] Avg prompt throughput: 21.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:05 llm_engine.py:878] Avg prompt throughput: 22.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:10 llm_engine.py:878] Avg prompt throughput: 22.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:20 llm_engine.py:878] Avg prompt throughput: 19.1 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
26it [51:33, 225.64s/it]NOACC! variant => validate prob: 0.1913912767807774 => 0.1913912767807774
Example index 25
Example time cost:  5.05 min
ALL examples time cost:  51.55 min
Origin CodeBLEU: 0.37959872056661303
Attacked CodeBLEU: 0.1913912767807774
Greedy_query_times:  118
Ga_query_times:  0
ALL query times:  932




INFO 02-28 19:39:25 llm_engine.py:878] Avg prompt throughput: 17.1 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:35 llm_engine.py:878] Avg prompt throughput: 17.3 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:40 llm_engine.py:878] Avg prompt throughput: 17.4 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:45 llm_engine.py:878] Avg prompt throughput: 17.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:39:50 llm_engine.py:878] Avg prompt throughput: 10.7 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! request => update prob: 1.0 => 0.19827359233036074
INFO 02-28 19:39:55 llm_engine.py:878] Avg prompt throughput: 23.6 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
27it [52:08, 168.66s/it]ACC! deleteDocumentationVersion => begin prob: 0.19827359233036074 => 0.1478631136068262
Example index 26
Example time cost:  0.59 min
ALL examples time cost:  52.15 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  1050




INFO 02-28 19:40:00 llm_engine.py:878] Avg prompt throughput: 46.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:05 llm_engine.py:878] Avg prompt throughput: 39.3 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:10 llm_engine.py:878] Avg prompt throughput: 27.4 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:15 llm_engine.py:878] Avg prompt throughput: 44.6 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:20 llm_engine.py:878] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:25 llm_engine.py:878] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:30 llm_engine.py:878] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:35 llm_engine.py:878] Avg prompt throughput: 28.5 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:40 llm_engine.py:878] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! other => equals prob: 0.8350945497872 => 0.5831189519356865
INFO 02-28 19:40:45 llm_engine.py:878] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:50 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:40:55 llm_engine.py:878] Avg prompt throughput: 43.5 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:00 llm_engine.py:878] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! obj => other prob: 0.5831189519356865 => 0.5020147835651844
INFO 02-28 19:41:05 llm_engine.py:878] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
NOACC! equals => equals prob: 0.5020147835651844 => 0.5833419465143036
INFO 02-28 19:41:10 llm_engine.py:878] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:15 llm_engine.py:878] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:20 llm_engine.py:878] Avg prompt throughput: 44.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:25 llm_engine.py:878] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:30 llm_engine.py:878] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:35 llm_engine.py:878] Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:40 llm_engine.py:878] Avg prompt throughput: 27.6 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:45 llm_engine.py:878] Avg prompt throughput: 22.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:50 llm_engine.py:878] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:41:55 llm_engine.py:878] Avg prompt throughput: 25.2 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
28it [54:08, 154.11s/it]ACC! i => object prob: 0.5020147835651844 => 0.396892236284509
Example index 27
Example time cost:  2.0 min
ALL examples time cost:  54.15 min
Origin CodeBLEU: 0.8350945497872
Attacked CodeBLEU: 0.396892236284509
Greedy_query_times:  57
Ga_query_times:  0
ALL query times:  1069




INFO 02-28 19:42:00 llm_engine.py:878] Avg prompt throughput: 9.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:10 llm_engine.py:878] Avg prompt throughput: 17.9 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:15 llm_engine.py:878] Avg prompt throughput: 10.7 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! getInstanceAccessDetails => get prob: 1.0 => 0.9017295359335316
INFO 02-28 19:42:20 llm_engine.py:878] Avg prompt throughput: 16.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:35 llm_engine.py:878] Avg prompt throughput: 16.7 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:40 llm_engine.py:878] Avg prompt throughput: 23.7 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
29it [54:55, 121.72s/it]ACC! request => argument prob: 0.9017295359335316 => 0.1478631136068262
Example index 28
Example time cost:  0.77 min
ALL examples time cost:  54.92 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  1126




INFO 02-28 19:42:45 llm_engine.py:878] Avg prompt throughput: 20.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:50 llm_engine.py:878] Avg prompt throughput: 32.9 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:42:55 llm_engine.py:878] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:00 llm_engine.py:878] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:05 llm_engine.py:878] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:10 llm_engine.py:878] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:15 llm_engine.py:878] Avg prompt throughput: 40.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! shape => build prob: 0.7704109805806191 => 0.5200339363361424
INFO 02-28 19:43:20 llm_engine.py:878] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:25 llm_engine.py:878] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:30 llm_engine.py:878] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:35 llm_engine.py:878] Avg prompt throughput: 38.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! anchor => c prob: 0.5200339363361424 => 0.30213032571304826
INFO 02-28 19:43:40 llm_engine.py:878] Avg prompt throughput: 36.2 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
30it [55:56, 103.62s/it]NOACC! createPolygon => shape prob: 0.30213032571304826 => 0.30408327715508043
Example index 29
Example time cost:  1.02 min
ALL examples time cost:  55.94 min
Origin CodeBLEU: 0.7704109805806191
Attacked CodeBLEU: 0.30213032571304826
Greedy_query_times:  35
Ga_query_times:  0
ALL query times:  1144




INFO 02-28 19:43:45 llm_engine.py:878] Avg prompt throughput: 35.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:43:50 llm_engine.py:878] Avg prompt throughput: 48.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
31it [56:06, 75.49s/it] ACC! sheetIndex => sheet prob: 1.0 => 0.5332467064778329
NOACC! getSheetName => text prob: 0.5332467064778329 => 0.5606803453800826
Example index 30
Example time cost:  0.16 min
ALL examples time cost:  56.1 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5332467064778329
Greedy_query_times:  14
Ga_query_times:  0
ALL query times:  1179




INFO 02-28 19:43:55 llm_engine.py:878] Avg prompt throughput: 33.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:05 llm_engine.py:878] Avg prompt throughput: 16.3 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:10 llm_engine.py:878] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 41.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! getDashboard => get prob: 1.0 => 0.9017295359335316
INFO 02-28 19:44:15 llm_engine.py:878] Avg prompt throughput: 16.5 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:20 llm_engine.py:878] Avg prompt throughput: 28.4 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:25 llm_engine.py:878] Avg prompt throughput: 10.7 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:30 llm_engine.py:878] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
32it [56:44, 64.33s/it]ACC! request => parent prob: 0.9017295359335316 => 0.1478631136068262
Example index 31
Example time cost:  0.64 min
ALL examples time cost:  56.74 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  1193




INFO 02-28 19:44:35 llm_engine.py:878] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:45 llm_engine.py:878] Avg prompt throughput: 15.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:50 llm_engine.py:878] Avg prompt throughput: 16.6 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:44:56 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:06 llm_engine.py:878] Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
33it [57:23, 56.64s/it]ACC! request => update prob: 1.0 => 0.19827359233036074
ACC! associateSigninDelegateGroupsWithAccount => create prob: 0.19827359233036074 => 0.1478631136068262
Example index 32
Example time cost:  0.65 min
ALL examples time cost:  57.39 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  1212




INFO 02-28 19:45:11 llm_engine.py:878] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:16 llm_engine.py:878] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:21 llm_engine.py:878] Avg prompt throughput: 33.3 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:26 llm_engine.py:878] Avg prompt throughput: 45.5 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:31 llm_engine.py:878] Avg prompt throughput: 28.8 tokens/s, Avg generation throughput: 43.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:36 llm_engine.py:878] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:41 llm_engine.py:878] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:46 llm_engine.py:878] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! mbr => process prob: 0.7477340149807571 => 0.600283918624892
INFO 02-28 19:45:51 llm_engine.py:878] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:45:56 llm_engine.py:878] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:01 llm_engine.py:878] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 43.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:06 llm_engine.py:878] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:11 llm_engine.py:878] Avg prompt throughput: 49.6 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:16 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:21 llm_engine.py:878] Avg prompt throughput: 48.1 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:26 llm_engine.py:878] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! br => 0 prob: 0.600283918624892 => 0.44045325339688346
INFO 02-28 19:46:31 llm_engine.py:878] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:36 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:41 llm_engine.py:878] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:46 llm_engine.py:878] Avg prompt throughput: 44.2 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:51 llm_engine.py:878] Avg prompt throughput: 30.4 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:46:56 llm_engine.py:878] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:01 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:06 llm_engine.py:878] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! j => process prob: 0.44045325339688346 => 0.32495331302890207
INFO 02-28 19:47:11 llm_engine.py:878] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
34it [59:27, 76.92s/it]NOACC! addMultipleBlanks => process prob: 0.32495331302890207 => 0.38384937903344274
Example index 33
Example time cost:  2.07 min
ALL examples time cost:  59.46 min
Origin CodeBLEU: 0.7477340149807571
Attacked CodeBLEU: 0.32495331302890207
Greedy_query_times:  61
Ga_query_times:  0
ALL query times:  1229




INFO 02-28 19:47:16 llm_engine.py:878] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:21 llm_engine.py:878] Avg prompt throughput: 32.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:26 llm_engine.py:878] Avg prompt throughput: 35.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:31 llm_engine.py:878] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:36 llm_engine.py:878] Avg prompt throughput: 36.2 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:41 llm_engine.py:878] Avg prompt throughput: 36.3 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:46 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:51 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:47:56 llm_engine.py:878] Avg prompt throughput: 38.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:01 llm_engine.py:878] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:06 llm_engine.py:878] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:11 llm_engine.py:878] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:16 llm_engine.py:878] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:21 llm_engine.py:878] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:26 llm_engine.py:878] Avg prompt throughput: 39.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! k => value prob: 0.4818723679792141 => 0.3483447480489534
INFO 02-28 19:48:31 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:36 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:41 llm_engine.py:878] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:46 llm_engine.py:878] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:51 llm_engine.py:878] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:48:56 llm_engine.py:878] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:01 llm_engine.py:878] Avg prompt throughput: 36.3 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:06 llm_engine.py:878] Avg prompt throughput: 35.5 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:11 llm_engine.py:878] Avg prompt throughput: 34.6 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:16 llm_engine.py:878] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:21 llm_engine.py:878] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! apos => value prob: 0.3483447480489534 => 0.2876157944885057
INFO 02-28 19:49:26 llm_engine.py:878] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:31 llm_engine.py:878] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
NOACC! quote => Q prob: 0.2876157944885057 => 0.2876157944885057
INFO 02-28 19:49:36 llm_engine.py:878] Avg prompt throughput: 37.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:41 llm_engine.py:878] Avg prompt throughput: 35.8 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:46 llm_engine.py:878] Avg prompt throughput: 34.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:51 llm_engine.py:878] Avg prompt throughput: 32.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:49:56 llm_engine.py:878] Avg prompt throughput: 30.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:01 llm_engine.py:878] Avg prompt throughput: 29.2 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! string => line prob: 0.2876157944885057 => 0.2720884659591004
INFO 02-28 19:50:06 llm_engine.py:878] Avg prompt throughput: 28.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:11 llm_engine.py:878] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:16 llm_engine.py:878] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:21 llm_engine.py:878] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:26 llm_engine.py:878] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:31 llm_engine.py:878] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:36 llm_engine.py:878] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
35it [1:02:52, 115.41s/it]ACC! sb => line prob: 0.2720884659591004 => 0.2641292326948214
Example index 34
Example time cost:  3.42 min
ALL examples time cost:  62.88 min
Origin CodeBLEU: 0.4818723679792141
Attacked CodeBLEU: 0.2641292326948214
Greedy_query_times:  82
Ga_query_times:  0
ALL query times:  1290




INFO 02-28 19:50:41 llm_engine.py:878] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:50:46 llm_engine.py:878] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! putInt => allocate prob: 0.5596783415809894 => 0.2423066949255656
INFO 02-28 19:50:51 llm_engine.py:878] Avg prompt throughput: 29.1 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
36it [1:03:06, 84.83s/it] NOACC! value => index prob: 0.2423066949255656 => 0.2423066949255656
Example index 35
Example time cost:  0.22 min
ALL examples time cost:  63.1 min
Origin CodeBLEU: 0.5596783415809894
Attacked CodeBLEU: 0.2423066949255656
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  1372




INFO 02-28 19:50:56 llm_engine.py:878] Avg prompt throughput: 9.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:01 llm_engine.py:878] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:26 llm_engine.py:878] Avg prompt throughput: 41.8 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:52 llm_engine.py:878] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:51:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:07 llm_engine.py:878] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:27 llm_engine.py:878] Avg prompt throughput: 34.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:42 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:52:57 llm_engine.py:878] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
ACC! _nColumns => 2 prob: 1.0 => 0.7363994780460408
INFO 02-28 19:53:12 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:27 llm_engine.py:878] Avg prompt throughput: 33.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:37 llm_engine.py:878] Avg prompt throughput: 35.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:47 llm_engine.py:878] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:53:57 llm_engine.py:878] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:07 llm_engine.py:878] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
ACC! _nRows => c prob: 0.7363994780460408 => 0.6254110977536961
INFO 02-28 19:54:17 llm_engine.py:878] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:27 llm_engine.py:878] Avg prompt throughput: 36.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:37 llm_engine.py:878] Avg prompt throughput: 35.1 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:47 llm_engine.py:878] Avg prompt throughput: 33.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:54:57 llm_engine.py:878] Avg prompt throughput: 32.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:02 llm_engine.py:878] Avg prompt throughput: 46.9 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:12 llm_engine.py:878] Avg prompt throughput: 45.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
NOACC! vv => data prob: 0.6254110977536961 => 0.6254110977536961
INFO 02-28 19:55:27 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:32 llm_engine.py:878] Avg prompt throughput: 46.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:42 llm_engine.py:878] Avg prompt throughput: 42.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:52 llm_engine.py:878] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:55:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:02 llm_engine.py:878] Avg prompt throughput: 35.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:12 llm_engine.py:878] Avg prompt throughput: 33.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:17 llm_engine.py:878] Avg prompt throughput: 48.1 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:27 llm_engine.py:878] Avg prompt throughput: 43.5 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:37 llm_engine.py:878] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:47 llm_engine.py:878] Avg prompt throughput: 36.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:56:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
ACC! rowData => rows prob: 0.6254110977536961 => 0.5961554951967192
INFO 02-28 19:56:57 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:02 llm_engine.py:878] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
ACC! values2d => data prob: 0.5961554951967192 => 0.5198497305263048
INFO 02-28 19:57:12 llm_engine.py:878] Avg prompt throughput: 33.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:17 llm_engine.py:878] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:27 llm_engine.py:878] Avg prompt throughput: 32.4 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:32 llm_engine.py:878] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:42 llm_engine.py:878] Avg prompt throughput: 31.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:47 llm_engine.py:878] Avg prompt throughput: 39.6 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 19:57:57 llm_engine.py:878] Avg prompt throughput: 30.7 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:02 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:12 llm_engine.py:878] Avg prompt throughput: 29.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:17 llm_engine.py:878] Avg prompt throughput: 36.6 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:22 llm_engine.py:878] Avg prompt throughput: 47.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:32 llm_engine.py:878] Avg prompt throughput: 34.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:37 llm_engine.py:878] Avg prompt throughput: 44.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! getValueIndex => array prob: 0.5198497305263048 => 0.4681571038218245
INFO 02-28 19:58:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:48 llm_engine.py:878] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:58:58 llm_engine.py:878] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:08 llm_engine.py:878] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:18 llm_engine.py:878] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:28 llm_engine.py:878] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:38 llm_engine.py:878] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:43 llm_engine.py:878] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:53 llm_engine.py:878] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 19:59:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:03 llm_engine.py:878] Avg prompt throughput: 35.8 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:13 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
ACC! _arrayValues => result prob: 0.4681571038218245 => 0.40352135028990055
INFO 02-28 20:00:23 llm_engine.py:878] Avg prompt throughput: 33.4 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:33 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:38 llm_engine.py:878] Avg prompt throughput: 44.8 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:48 llm_engine.py:878] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:00:58 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:03 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:13 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:23 llm_engine.py:878] Avg prompt throughput: 35.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:33 llm_engine.py:878] Avg prompt throughput: 30.3 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:43 llm_engine.py:878] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:48 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:01:58 llm_engine.py:878] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
ACC! _reserved0Int => result prob: 0.40352135028990055 => 0.4016419509930895
INFO 02-28 20:02:08 llm_engine.py:878] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:13 llm_engine.py:878] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:23 llm_engine.py:878] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:33 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:38 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:43 llm_engine.py:878] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:53 llm_engine.py:878] Avg prompt throughput: 30.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:02:58 llm_engine.py:878] Avg prompt throughput: 38.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:03 llm_engine.py:878] Avg prompt throughput: 49.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:13 llm_engine.py:878] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:18 llm_engine.py:878] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:28 llm_engine.py:878] Avg prompt throughput: 34.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:33 llm_engine.py:878] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:43 llm_engine.py:878] Avg prompt throughput: 35.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
NOACC! _reserved1Short => n prob: 0.4016419509930895 => 0.4016419509930895
INFO 02-28 20:03:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:53 llm_engine.py:878] Avg prompt throughput: 58.1 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:03:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:03 llm_engine.py:878] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:13 llm_engine.py:878] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:18 llm_engine.py:878] Avg prompt throughput: 48.4 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:28 llm_engine.py:878] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:33 llm_engine.py:878] Avg prompt throughput: 48.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:43 llm_engine.py:878] Avg prompt throughput: 29.6 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:48 llm_engine.py:878] Avg prompt throughput: 36.8 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:04:58 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:03 llm_engine.py:878] Avg prompt throughput: 30.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:08 llm_engine.py:878] Avg prompt throughput: 46.1 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:18 llm_engine.py:878] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
NOACC! _reserved2Byte => wrap prob: 0.4016419509930895 => 0.4016419509930895
INFO 02-28 20:05:28 llm_engine.py:878] Avg prompt throughput: 28.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:34 llm_engine.py:878] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:44 llm_engine.py:878] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! nColumns => row prob: 0.4016419509930895 => 0.3866735157522173
INFO 02-28 20:05:49 llm_engine.py:878] Avg prompt throughput: 52.9 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:54 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:05:59 llm_engine.py:878] Avg prompt throughput: 34.8 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:04 llm_engine.py:878] Avg prompt throughput: 52.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:14 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
NOACC! nRows => n prob: 0.3866735157522173 => 0.39815950616528256
INFO 02-28 20:06:24 llm_engine.py:878] Avg prompt throughput: 34.1 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:29 llm_engine.py:878] Avg prompt throughput: 43.9 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:39 llm_engine.py:878] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:44 llm_engine.py:878] Avg prompt throughput: 55.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:54 llm_engine.py:878] Avg prompt throughput: 34.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:06:59 llm_engine.py:878] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:04 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:09 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:14 llm_engine.py:878] Avg prompt throughput: 47.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! r => stride prob: 0.3866735157522173 => 0.3235016871497224
INFO 02-28 20:07:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:24 llm_engine.py:878] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:34 llm_engine.py:878] Avg prompt throughput: 31.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:39 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:44 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:49 llm_engine.py:878] Avg prompt throughput: 34.5 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:54 llm_engine.py:878] Avg prompt throughput: 46.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:07:59 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:04 llm_engine.py:878] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:14 llm_engine.py:878] Avg prompt throughput: 45.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:24 llm_engine.py:878] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
37it [1:20:40, 375.70s/it]ACC! c => rows prob: 0.3235016871497224 => 0.25841297101899696
Example index 36
Example time cost:  17.57 min
ALL examples time cost:  80.68 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.25841297101899696
Greedy_query_times:  327
Ga_query_times:  0
ALL query times:  1389




INFO 02-28 20:08:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:34 llm_engine.py:878] Avg prompt throughput: 9.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:39 llm_engine.py:878] Avg prompt throughput: 14.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:44 llm_engine.py:878] Avg prompt throughput: 10.8 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! getIceServerConfig => result prob: 1.0 => 0.9017295359335316
INFO 02-28 20:08:49 llm_engine.py:878] Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:54 llm_engine.py:878] Avg prompt throughput: 28.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:08:59 llm_engine.py:878] Avg prompt throughput: 18.8 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
38it [1:21:14, 273.25s/it]ACC! request => input prob: 0.9017295359335316 => 0.1478631136068262
Example index 37
Example time cost:  0.57 min
ALL examples time cost:  81.25 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  1716




INFO 02-28 20:09:04 llm_engine.py:878] Avg prompt throughput: 33.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
39it [1:21:20, 192.89s/it]ACC! toString => value prob: 0.8487156940347949 => 0.07323671807974534
Example index 38
Example time cost:  0.09 min
ALL examples time cost:  81.34 min
Origin CodeBLEU: 0.8487156940347949
Attacked CodeBLEU: 0.07323671807974534
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  1735




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:09:09 llm_engine.py:878] Avg prompt throughput: 38.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:09:14 llm_engine.py:878] Avg prompt throughput: 36.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:09:19 llm_engine.py:878] Avg prompt throughput: 45.1 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! field => id prob: 0.4887303866544812 => 0.30710288280345577
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:09:24 llm_engine.py:878] Avg prompt throughput: 42.9 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
40it [1:21:38, 140.52s/it]41it [1:21:42, 99.44s/it] WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! toString => get prob: 0.30710288280345577 => 0.20655843356587675
Example index 39
Example time cost:  0.31 min
ALL examples time cost:  81.64 min
Origin CodeBLEU: 0.4887303866544812
Attacked CodeBLEU: 0.20655843356587675
Greedy_query_times:  24
Ga_query_times:  0
ALL query times:  1742




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! incRef => clear prob: 0.5311706625951745 => 0.23538955562800784
Example index 40
Example time cost:  0.06 min
ALL examples time cost:  81.7 min
Origin CodeBLEU: 0.5311706625951745
Attacked CodeBLEU: 0.23538955562800784
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  1766




INFO 02-28 20:09:29 llm_engine.py:878] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:09:34 llm_engine.py:878] Avg prompt throughput: 16.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:09:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:09:44 llm_engine.py:878] Avg prompt throughput: 13.2 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:09:49 llm_engine.py:878] Avg prompt throughput: 11.8 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:09:54 llm_engine.py:878] Avg prompt throughput: 21.5 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:09:59 llm_engine.py:878] Avg prompt throughput: 17.9 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:04 llm_engine.py:878] Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! request => instruction prob: 1.0 => 0.19827359233036074
INFO 02-28 20:10:09 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
42it [1:22:26, 82.94s/it]ACC! updateConfigurationSetSendingEnabled => update prob: 0.19827359233036074 => 0.1478631136068262
Example index 41
Example time cost:  0.74 min
ALL examples time cost:  82.44 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  22
Ga_query_times:  0
ALL query times:  1773




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:10:14 llm_engine.py:878] Avg prompt throughput: 44.3 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
43it [1:22:31, 59.55s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getNextXBATChainOffset => size prob: 0.75 => 0.11628099221607749
Example index 42
Example time cost:  0.08 min
ALL examples time cost:  82.53 min
Origin CodeBLEU: 0.75
Attacked CodeBLEU: 0.11628099221607749
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  1795




INFO 02-28 20:10:19 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:24 llm_engine.py:878] Avg prompt throughput: 47.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:29 llm_engine.py:878] Avg prompt throughput: 28.3 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:34 llm_engine.py:878] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:39 llm_engine.py:878] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:44 llm_engine.py:878] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:49 llm_engine.py:878] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! tp => this prob: 0.7041283528879904 => 0.42873162894040856
INFO 02-28 20:10:54 llm_engine.py:878] Avg prompt throughput: 36.5 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:10:59 llm_engine.py:878] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:04 llm_engine.py:878] Avg prompt throughput: 23.7 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! pow10 => shift prob: 0.42873162894040856 => 0.312094545251008
INFO 02-28 20:11:09 llm_engine.py:878] Avg prompt throughput: 33.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:14 llm_engine.py:878] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
44it [1:23:28, 58.75s/it]ACC! multiplyByPowerOfTen => pow prob: 0.312094545251008 => 0.3014498909340029
Example index 43
Example time cost:  0.95 min
ALL examples time cost:  83.47 min
Origin CodeBLEU: 0.7041283528879904
Attacked CodeBLEU: 0.3014498909340029
Greedy_query_times:  30
Ga_query_times:  0
ALL query times:  1802




INFO 02-28 20:11:19 llm_engine.py:878] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:24 llm_engine.py:878] Avg prompt throughput: 48.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:29 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:34 llm_engine.py:878] Avg prompt throughput: 23.3 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:39 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:44 llm_engine.py:878] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! toString => get prob: 0.5886032898050407 => 0.34381180338540346
INFO 02-28 20:11:49 llm_engine.py:878] Avg prompt throughput: 36.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:54 llm_engine.py:878] Avg prompt throughput: 24.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:11:59 llm_engine.py:878] Avg prompt throughput: 20.5 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:04 llm_engine.py:878] Avg prompt throughput: 35.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:09 llm_engine.py:878] Avg prompt throughput: 21.6 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:14 llm_engine.py:878] Avg prompt throughput: 20.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
NOACC! b => get prob: 0.34381180338540346 => 0.34381180338540346
INFO 02-28 20:12:19 llm_engine.py:878] Avg prompt throughput: 35.1 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:24 llm_engine.py:878] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:29 llm_engine.py:878] Avg prompt throughput: 21.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:35 llm_engine.py:878] Avg prompt throughput: 19.7 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:40 llm_engine.py:878] Avg prompt throughput: 36.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:45 llm_engine.py:878] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:50 llm_engine.py:878] Avg prompt throughput: 23.4 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:12:55 llm_engine.py:878] Avg prompt throughput: 19.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
NOACC! l => n prob: 0.34381180338540346 => 0.34381180338540346
INFO 02-28 20:13:00 llm_engine.py:878] Avg prompt throughput: 35.5 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:05 llm_engine.py:878] Avg prompt throughput: 22.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:10 llm_engine.py:878] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:15 llm_engine.py:878] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:20 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:25 llm_engine.py:878] Avg prompt throughput: 22.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:30 llm_engine.py:878] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:35 llm_engine.py:878] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:40 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:45 llm_engine.py:878] Avg prompt throughput: 22.6 tokens/s, Avg generation throughput: 43.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
45it [1:25:58, 86.20s/it]ACC! i => reverse prob: 0.34381180338540346 => 0.23215007647868072
Example index 44
Example time cost:  2.5 min
ALL examples time cost:  85.98 min
Origin CodeBLEU: 0.5886032898050407
Attacked CodeBLEU: 0.23215007647868072
Greedy_query_times:  71
Ga_query_times:  0
ALL query times:  1832




INFO 02-28 20:13:50 llm_engine.py:878] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 43.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:13:55 llm_engine.py:878] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:14:00 llm_engine.py:878] Avg prompt throughput: 44.1 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! fetcher => create prob: 0.37015346772113666 => 0.3522905558364528
INFO 02-28 20:14:05 llm_engine.py:878] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
46it [1:26:18, 66.33s/it]NOACC! withFetcher => create prob: 0.3522905558364528 => 0.3522905558364528
Example index 45
Example time cost:  0.33 min
ALL examples time cost:  86.31 min
Origin CodeBLEU: 0.37015346772113666
Attacked CodeBLEU: 0.3522905558364528
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  1903




INFO 02-28 20:14:10 llm_engine.py:878] Avg prompt throughput: 29.2 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! pm => m prob: 0.6392123257003388 => 0.5923066949255656
INFO 02-28 20:14:15 llm_engine.py:878] Avg prompt throughput: 46.4 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
47it [1:26:33, 50.77s/it]NOACC! progressMonitor => m prob: 0.5923066949255656 => 0.5923066949255656
NOACC! setProgressMonitor => add prob: 0.5923066949255656 => 0.5923066949255656
Example index 46
Example time cost:  0.24 min
ALL examples time cost:  86.55 min
Origin CodeBLEU: 0.6392123257003388
Attacked CodeBLEU: 0.5923066949255656
Greedy_query_times:  31
Ga_query_times:  0
ALL query times:  1921




INFO 02-28 20:14:20 llm_engine.py:878] Avg prompt throughput: 48.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:14:25 llm_engine.py:878] Avg prompt throughput: 43.5 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! reset => skip prob: 0.4263918069531467 => 0.4173200636525969
INFO 02-28 20:14:30 llm_engine.py:878] Avg prompt throughput: 42.2 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
48it [1:26:43, 38.80s/it]NOACC! ptr => next prob: 0.4173200636525969 => 0.4173200636525969
Example index 47
Example time cost:  0.18 min
ALL examples time cost:  86.73 min
Origin CodeBLEU: 0.4263918069531467
Attacked CodeBLEU: 0.4173200636525969
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  1952




INFO 02-28 20:14:35 llm_engine.py:878] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
49it [1:26:51, 29.39s/it]ACC! previous => next prob: 0.8822062130497406 => 0.5418875206508836
Example index 48
Example time cost:  0.12 min
ALL examples time cost:  86.86 min
Origin CodeBLEU: 0.8822062130497406
Attacked CodeBLEU: 0.5418875206508836
Greedy_query_times:  8
Ga_query_times:  0
ALL query times:  1969




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:14:40 llm_engine.py:878] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
50it [1:26:53, 21.26s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getNewPrefix => suffix prob: 0.75 => 0.3896861490546798
Example index 49
Example time cost:  0.04 min
ALL examples time cost:  86.89 min
Origin CodeBLEU: 0.75
Attacked CodeBLEU: 0.3896861490546798
Greedy_query_times:  6
Ga_query_times:  0
ALL query times:  1977




INFO 02-28 20:14:45 llm_engine.py:878] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:14:50 llm_engine.py:878] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:14:55 llm_engine.py:878] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! value => i prob: 0.7527236931097129 => 0.5039976279934775
INFO 02-28 20:15:00 llm_engine.py:878] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:05 llm_engine.py:878] Avg prompt throughput: 33.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:10 llm_engine.py:878] Avg prompt throughput: 32.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! i => k prob: 0.5039976279934775 => 0.25138769592105425
INFO 02-28 20:15:15 llm_engine.py:878] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
51it [1:27:32, 26.43s/it]NOACC! indexOfValue => index prob: 0.25138769592105425 => 0.25138769592105425
Example index 50
Example time cost:  0.64 min
ALL examples time cost:  87.54 min
Origin CodeBLEU: 0.7527236931097129
Attacked CodeBLEU: 0.25138769592105425
Greedy_query_times:  32
Ga_query_times:  0
ALL query times:  1983




INFO 02-28 20:15:20 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:25 llm_engine.py:878] Avg prompt throughput: 43.4 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:35 llm_engine.py:878] Avg prompt throughput: 29.6 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:40 llm_engine.py:878] Avg prompt throughput: 34.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:45 llm_engine.py:878] Avg prompt throughput: 34.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:50 llm_engine.py:878] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:15:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:00 llm_engine.py:878] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:05 llm_engine.py:878] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:10 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:20 llm_engine.py:878] Avg prompt throughput: 29.8 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:25 llm_engine.py:878] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:35 llm_engine.py:878] Avg prompt throughput: 29.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:40 llm_engine.py:878] Avg prompt throughput: 36.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:50 llm_engine.py:878] Avg prompt throughput: 26.6 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:16:55 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! stems => s prob: 0.5848181299542891 => 0.42457561923564613
INFO 02-28 20:17:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:05 llm_engine.py:878] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:10 llm_engine.py:878] Avg prompt throughput: 33.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:20 llm_engine.py:878] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:25 llm_engine.py:878] Avg prompt throughput: 31.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:30 llm_engine.py:878] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! word => char prob: 0.42457561923564613 => 0.39858314089235874
INFO 02-28 20:17:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:40 llm_engine.py:878] Avg prompt throughput: 28.6 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:45 llm_engine.py:878] Avg prompt throughput: 36.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:17:55 llm_engine.py:878] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:05 llm_engine.py:878] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:10 llm_engine.py:878] Avg prompt throughput: 33.7 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:20 llm_engine.py:878] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! length => s prob: 0.39858314089235874 => 0.39756639003526495
INFO 02-28 20:18:25 llm_engine.py:878] Avg prompt throughput: 32.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:35 llm_engine.py:878] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:40 llm_engine.py:878] Avg prompt throughput: 32.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:50 llm_engine.py:878] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:18:55 llm_engine.py:878] Avg prompt throughput: 29.8 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:05 llm_engine.py:878] Avg prompt throughput: 23.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:10 llm_engine.py:878] Avg prompt throughput: 29.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:15 llm_engine.py:878] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:26 llm_engine.py:878] Avg prompt throughput: 28.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:31 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:41 llm_engine.py:878] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:46 llm_engine.py:878] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:19:56 llm_engine.py:878] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:01 llm_engine.py:878] Avg prompt throughput: 35.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
NOACC! deduped => str prob: 0.39756639003526495 => 0.41152130851095814
INFO 02-28 20:20:11 llm_engine.py:878] Avg prompt throughput: 29.1 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:16 llm_engine.py:878] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:26 llm_engine.py:878] Avg prompt throughput: 31.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:31 llm_engine.py:878] Avg prompt throughput: 43.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:41 llm_engine.py:878] Avg prompt throughput: 30.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:46 llm_engine.py:878] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:20:56 llm_engine.py:878] Avg prompt throughput: 28.3 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:01 llm_engine.py:878] Avg prompt throughput: 35.3 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:11 llm_engine.py:878] Avg prompt throughput: 29.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:21 llm_engine.py:878] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:26 llm_engine.py:878] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:36 llm_engine.py:878] Avg prompt throughput: 30.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:46 llm_engine.py:878] Avg prompt throughput: 27.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:51 llm_engine.py:878] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:21:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:01 llm_engine.py:878] Avg prompt throughput: 32.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! s => unique prob: 0.39756639003526495 => 0.3762418052379448
INFO 02-28 20:22:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:11 llm_engine.py:878] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:16 llm_engine.py:878] Avg prompt throughput: 30.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:26 llm_engine.py:878] Avg prompt throughput: 25.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:31 llm_engine.py:878] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:36 llm_engine.py:878] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:46 llm_engine.py:878] Avg prompt throughput: 27.5 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:51 llm_engine.py:878] Avg prompt throughput: 32.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:22:56 llm_engine.py:878] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:06 llm_engine.py:878] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:11 llm_engine.py:878] Avg prompt throughput: 31.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:21 llm_engine.py:878] Avg prompt throughput: 25.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:26 llm_engine.py:878] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:31 llm_engine.py:878] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! terms => stem prob: 0.3762418052379448 => 0.3248069480922803
INFO 02-28 20:23:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:41 llm_engine.py:878] Avg prompt throughput: 27.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
52it [1:35:59, 170.75s/it]NOACC! uniqueStems => stems prob: 0.3248069480922803 => 0.40211882613860916
Example index 51
Example time cost:  8.46 min
ALL examples time cost:  95.99 min
Origin CodeBLEU: 0.5848181299542891
Attacked CodeBLEU: 0.3248069480922803
Greedy_query_times:  170
Ga_query_times:  0
ALL query times:  2015




INFO 02-28 20:23:51 llm_engine.py:878] Avg prompt throughput: 11.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:23:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:01 llm_engine.py:878] Avg prompt throughput: 18.7 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:06 llm_engine.py:878] Avg prompt throughput: 16.7 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! getGatewayResponses => get prob: 1.0 => 0.9017295359335316
INFO 02-28 20:24:11 llm_engine.py:878] Avg prompt throughput: 15.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:16 llm_engine.py:878] Avg prompt throughput: 13.2 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:21 llm_engine.py:878] Avg prompt throughput: 23.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:26 llm_engine.py:878] Avg prompt throughput: 20.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:31 llm_engine.py:878] Avg prompt throughput: 17.5 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
53it [1:36:46, 133.51s/it]ACC! request => response prob: 0.9017295359335316 => 0.11101779823773752
Example index 52
Example time cost:  0.78 min
ALL examples time cost:  96.77 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  2185




INFO 02-28 20:24:36 llm_engine.py:878] Avg prompt throughput: 34.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:41 llm_engine.py:878] Avg prompt throughput: 22.6 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:46 llm_engine.py:878] Avg prompt throughput: 19.2 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:51 llm_engine.py:878] Avg prompt throughput: 31.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:24:56 llm_engine.py:878] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! currentBlockIndex => pos prob: 0.20932114398099816 => 0.20813066779052194
INFO 02-28 20:25:01 llm_engine.py:878] Avg prompt throughput: 42.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! setPosition => update prob: 0.20813066779052194 => 0.1985564117029503
INFO 02-28 20:25:06 llm_engine.py:878] Avg prompt throughput: 43.1 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:25:11 llm_engine.py:878] Avg prompt throughput: 33.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:25:16 llm_engine.py:878] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! currentBlock => value prob: 0.1985564117029503 => 0.18188974503628363
INFO 02-28 20:25:21 llm_engine.py:878] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:25:26 llm_engine.py:878] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! pos => pos prob: 0.18188974503628363 => 0.16522307836961697
INFO 02-28 20:25:31 llm_engine.py:878] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:25:36 llm_engine.py:878] Avg prompt throughput: 45.3 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
54it [1:37:52, 113.40s/it]NOACC! currentBlockUpto => update prob: 0.16522307836961697 => 0.16522307836961697
Example index 53
Example time cost:  1.11 min
ALL examples time cost:  97.88 min
Origin CodeBLEU: 0.20932114398099816
Attacked CodeBLEU: 0.16522307836961697
Greedy_query_times:  58
Ga_query_times:  0
ALL query times:  2205




INFO 02-28 20:25:41 llm_engine.py:878] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:25:46 llm_engine.py:878] Avg prompt throughput: 44.5 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:25:52 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:25:57 llm_engine.py:878] Avg prompt throughput: 35.4 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! s => ptr prob: 1.0 => 0.7748933555529813
INFO 02-28 20:26:02 llm_engine.py:878] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! skip => fill prob: 0.7748933555529813 => 0.6441874137120691
INFO 02-28 20:26:07 llm_engine.py:878] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:12 llm_engine.py:878] Avg prompt throughput: 36.8 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:17 llm_engine.py:878] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! ptr => cap prob: 0.6441874137120691 => 0.5289403784208992
INFO 02-28 20:26:22 llm_engine.py:878] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:27 llm_engine.py:878] Avg prompt throughput: 35.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
55it [1:38:40, 93.56s/it] 56it [1:38:44, 66.85s/it]ACC! n => available prob: 0.5289403784208992 => 0.41591772493837864
Example index 54
Example time cost:  0.79 min
ALL examples time cost:  98.67 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.41591772493837864
Greedy_query_times:  50
Ga_query_times:  0
ALL query times:  2263




ACC! bootstrapActionConfig => info prob: 1.0 => 0.5649787723081164
Example index 55
Example time cost:  0.08 min
ALL examples time cost:  98.74 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5649787723081164
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  2313




INFO 02-28 20:26:32 llm_engine.py:878] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:26:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:17 llm_engine.py:878] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
ACC! out => flush prob: 0.5952306139349939 => 0.4550577337860211
INFO 02-28 20:27:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:27:47 llm_engine.py:878] Avg prompt throughput: 40.8 tokens/s, Avg generation throughput: 42.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
57it [1:40:03, 70.63s/it]ACC! serialize => store prob: 0.4550577337860211 => 0.45202959166718426
Example index 56
Example time cost:  1.32 min
ALL examples time cost:  100.07 min
Origin CodeBLEU: 0.5952306139349939
Attacked CodeBLEU: 0.45202959166718426
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  2320




INFO 02-28 20:27:52 llm_engine.py:878] Avg prompt throughput: 21.3 tokens/s, Avg generation throughput: 43.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
NOACC! lastIndexOf => find prob: 0.5923066949255656 => 0.5923066949255656
INFO 02-28 20:27:57 llm_engine.py:878] Avg prompt throughput: 36.0 tokens/s, Avg generation throughput: 41.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:02 llm_engine.py:878] Avg prompt throughput: 45.3 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
58it [1:40:16, 53.09s/it]ACC! string => length prob: 0.5923066949255656 => 0.5884845294124772
Example index 57
Example time cost:  0.2 min
ALL examples time cost:  100.27 min
Origin CodeBLEU: 0.5923066949255656
Attacked CodeBLEU: 0.5884845294124772
Greedy_query_times:  22
Ga_query_times:  0
ALL query times:  2338




INFO 02-28 20:28:07 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
59it [1:40:24, 39.73s/it]ACC! object => s prob: 0.7639220528525453 => 0.5490010153642175
ACC! add => adds prob: 0.5490010153642175 => 0.5259279231245451
Example index 58
Example time cost:  0.14 min
ALL examples time cost:  100.41 min
Origin CodeBLEU: 0.7639220528525453
Attacked CodeBLEU: 0.5259279231245451
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  2360




INFO 02-28 20:28:12 llm_engine.py:878] Avg prompt throughput: 45.6 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:17 llm_engine.py:878] Avg prompt throughput: 48.0 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:22 llm_engine.py:878] Avg prompt throughput: 46.1 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:27 llm_engine.py:878] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:32 llm_engine.py:878] Avg prompt throughput: 44.5 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:37 llm_engine.py:878] Avg prompt throughput: 44.8 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:42 llm_engine.py:878] Avg prompt throughput: 43.5 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:47 llm_engine.py:878] Avg prompt throughput: 42.2 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! src => section prob: 0.48515383121590605 => 0.38945749578758104
INFO 02-28 20:28:52 llm_engine.py:878] Avg prompt throughput: 44.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:28:57 llm_engine.py:878] Avg prompt throughput: 31.9 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:02 llm_engine.py:878] Avg prompt throughput: 35.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:07 llm_engine.py:878] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! section => copy prob: 0.38945749578758104 => 0.2937999495390927
INFO 02-28 20:29:12 llm_engine.py:878] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:17 llm_engine.py:878] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:22 llm_engine.py:878] Avg prompt throughput: 48.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:27 llm_engine.py:878] Avg prompt throughput: 44.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:32 llm_engine.py:878] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:37 llm_engine.py:878] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:42 llm_engine.py:878] Avg prompt throughput: 35.9 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! res => target prob: 0.2937999495390927 => 0.2668055415547098
INFO 02-28 20:29:47 llm_engine.py:878] Avg prompt throughput: 36.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:52 llm_engine.py:878] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:29:57 llm_engine.py:878] Avg prompt throughput: 49.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! subsection => clone prob: 0.2668055415547098 => 0.2631089621939647
INFO 02-28 20:30:02 llm_engine.py:878] Avg prompt throughput: 47.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:30:07 llm_engine.py:878] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
60it [1:42:24, 63.67s/it]NOACC! unsetSection => update prob: 0.2631089621939647 => 0.3566828415919406
Example index 59
Example time cost:  1.99 min
ALL examples time cost:  102.4 min
Origin CodeBLEU: 0.48515383121590605
Attacked CodeBLEU: 0.2631089621939647
Greedy_query_times:  96
Ga_query_times:  0
ALL query times:  2378




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:30:12 llm_engine.py:878] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
61it [1:42:26, 45.14s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getTagName => tag prob: 0.32111490519867136 => 0.18832906855132966
Example index 60
Example time cost:  0.03 min
ALL examples time cost:  102.44 min
Origin CodeBLEU: 0.32111490519867136
Attacked CodeBLEU: 0.18832906855132966
Greedy_query_times:  6
Ga_query_times:  0
ALL query times:  2474




INFO 02-28 20:30:17 llm_engine.py:878] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! addSubRecord => add prob: 0.8251908791628888 => 0.48794046675757735
INFO 02-28 20:30:22 llm_engine.py:878] Avg prompt throughput: 41.8 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! index => id prob: 0.48794046675757735 => 0.46895225640494964
INFO 02-28 20:30:27 llm_engine.py:878] Avg prompt throughput: 45.7 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:30:32 llm_engine.py:878] Avg prompt throughput: 48.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
62it [1:42:46, 37.59s/it]ACC! element => insert prob: 0.46895225640494964 => 0.4679974212335175
Example index 61
Example time cost:  0.33 min
ALL examples time cost:  102.77 min
Origin CodeBLEU: 0.8251908791628888
Attacked CodeBLEU: 0.4679974212335175
Greedy_query_times:  30
Ga_query_times:  0
ALL query times:  2480




INFO 02-28 20:30:37 llm_engine.py:878] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:30:42 llm_engine.py:878] Avg prompt throughput: 46.6 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
63it [1:42:59, 30.38s/it]ACC! o => id prob: 0.7236559914567413 => 0.2839733615922323
ACC! remove => equals prob: 0.2839733615922323 => 0.2142513657500822
Example index 62
Example time cost:  0.23 min
ALL examples time cost:  102.99 min
Origin CodeBLEU: 0.7236559914567413
Attacked CodeBLEU: 0.2142513657500822
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  2510




INFO 02-28 20:30:47 llm_engine.py:878] Avg prompt throughput: 48.1 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:30:52 llm_engine.py:878] Avg prompt throughput: 33.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! create => apply prob: 1.0 => 0.8010709942840171
INFO 02-28 20:30:57 llm_engine.py:878] Avg prompt throughput: 45.8 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
64it [1:43:14, 25.58s/it]ACC! input => wrap prob: 0.8010709942840171 => 0.5806306203097971
Example index 63
Example time cost:  0.24 min
ALL examples time cost:  103.23 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5806306203097971
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  2531




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:31:02 llm_engine.py:878] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
65it [1:43:16, 18.70s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! length => size prob: 0.1384707185221477 => 0.10856394733451133
Example index 64
Example time cost:  0.04 min
ALL examples time cost:  103.28 min
Origin CodeBLEU: 0.1384707185221477
Attacked CodeBLEU: 0.10856394733451133
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  2548




INFO 02-28 20:31:07 llm_engine.py:878] Avg prompt throughput: 31.3 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
ACC! newValue => value prob: 1.0 => 0.5039590217597717
INFO 02-28 20:31:12 llm_engine.py:878] Avg prompt throughput: 47.8 tokens/s, Avg generation throughput: 38.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
66it [1:43:29, 16.89s/it]NOACC! value => Value prob: 0.5039590217597717 => 0.5039590217597717
NOACC! setValue => update prob: 0.5039590217597717 => 0.5089733615922323
Example index 65
Example time cost:  0.21 min
ALL examples time cost:  103.49 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5039590217597717
Greedy_query_times:  29
Ga_query_times:  0
ALL query times:  2555




INFO 02-28 20:31:17 llm_engine.py:878] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 38.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:31:22 llm_engine.py:878] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! newSource => source prob: 1.0 => 0.6681659818470707
INFO 02-28 20:31:27 llm_engine.py:878] Avg prompt throughput: 44.5 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
67it [1:43:43, 16.10s/it]ACC! oldSource => source prob: 0.6681659818470707 => 0.5327851976169589
Example index 66
Example time cost:  0.24 min
ALL examples time cost:  103.73 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5327851976169589
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  2584




INFO 02-28 20:31:32 llm_engine.py:878] Avg prompt throughput: 34.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:31:37 llm_engine.py:878] Avg prompt throughput: 33.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:31:42 llm_engine.py:878] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! i => entry prob: 0.531525816665526 => 0.40856076542023584
INFO 02-28 20:31:47 llm_engine.py:878] Avg prompt throughput: 42.7 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
68it [1:44:02, 16.83s/it]69it [1:44:03, 12.15s/it]NOACC! get => entry prob: 0.40856076542023584 => 0.40856076542023584
Example index 67
Example time cost:  0.31 min
ALL examples time cost:  104.04 min
Origin CodeBLEU: 0.531525816665526
Attacked CodeBLEU: 0.40856076542023584
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  2603




Example index 68
Example time cost:  0.02 min
ALL examples time cost:  104.06 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 1.0
Greedy_query_times:  1
Ga_query_times:  0
ALL query times:  2623




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 20:31:52 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
70it [1:44:06,  9.33s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! isDeltaBaseAsOffset => get prob: 0.75 => 0.39583421659869744
Example index 69
Example time cost:  0.05 min
ALL examples time cost:  104.1 min
Origin CodeBLEU: 0.75
Attacked CodeBLEU: 0.39583421659869744
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  2624




INFO 02-28 20:31:57 llm_engine.py:878] Avg prompt throughput: 27.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:07 llm_engine.py:878] Avg prompt throughput: 29.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:17 llm_engine.py:878] Avg prompt throughput: 34.5 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:27 llm_engine.py:878] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:38 llm_engine.py:878] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:43 llm_engine.py:878] Avg prompt throughput: 36.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:53 llm_engine.py:878] Avg prompt throughput: 31.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:32:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:03 llm_engine.py:878] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:08 llm_engine.py:878] Avg prompt throughput: 33.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
NOACC! next => next prob: 0.4787028451284312 => 0.4787028451284312
INFO 02-28 20:33:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:18 llm_engine.py:878] Avg prompt throughput: 29.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:28 llm_engine.py:878] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:33 llm_engine.py:878] Avg prompt throughput: 29.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:38 llm_engine.py:878] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:48 llm_engine.py:878] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:53 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:33:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
NOACC! previous => prev prob: 0.4787028451284312 => 0.4787028451284312
INFO 02-28 20:34:03 llm_engine.py:878] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:08 llm_engine.py:878] Avg prompt throughput: 33.8 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:18 llm_engine.py:878] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:23 llm_engine.py:878] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:33 llm_engine.py:878] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:38 llm_engine.py:878] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:48 llm_engine.py:878] Avg prompt throughput: 24.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:34:53 llm_engine.py:878] Avg prompt throughput: 30.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! link => null prob: 0.4787028451284312 => 0.44336200759924105
INFO 02-28 20:34:58 llm_engine.py:878] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:08 llm_engine.py:878] Avg prompt throughput: 28.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:13 llm_engine.py:878] Avg prompt throughput: 33.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:23 llm_engine.py:878] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:28 llm_engine.py:878] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:33 llm_engine.py:878] Avg prompt throughput: 35.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:43 llm_engine.py:878] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:48 llm_engine.py:878] Avg prompt throughput: 31.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:35:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
NOACC! pos => link prob: 0.44336200759924105 => 0.44336200759924105
INFO 02-28 20:35:58 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:03 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:13 llm_engine.py:878] Avg prompt throughput: 27.6 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:18 llm_engine.py:878] Avg prompt throughput: 34.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:28 llm_engine.py:878] Avg prompt throughput: 29.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:33 llm_engine.py:878] Avg prompt throughput: 36.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:43 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:48 llm_engine.py:878] Avg prompt throughput: 32.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:36:58 llm_engine.py:878] Avg prompt throughput: 28.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:03 llm_engine.py:878] Avg prompt throughput: 34.8 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
ACC! list => this prob: 0.44336200759924105 => 0.3307843703660092
INFO 02-28 20:37:13 llm_engine.py:878] Avg prompt throughput: 26.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:23 llm_engine.py:878] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:33 llm_engine.py:878] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:38 llm_engine.py:878] Avg prompt throughput: 33.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:48 llm_engine.py:878] Avg prompt throughput: 28.6 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:37:58 llm_engine.py:878] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:08 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:13 llm_engine.py:878] Avg prompt throughput: 32.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:23 llm_engine.py:878] Avg prompt throughput: 29.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
NOACC! size => position prob: 0.3307843703660092 => 0.3307843703660092
INFO 02-28 20:38:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:39 llm_engine.py:878] Avg prompt throughput: 24.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:44 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:49 llm_engine.py:878] Avg prompt throughput: 28.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:54 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:38:59 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:04 llm_engine.py:878] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:14 llm_engine.py:878] Avg prompt throughput: 24.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:24 llm_engine.py:878] Avg prompt throughput: 27.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:34 llm_engine.py:878] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:44 llm_engine.py:878] Avg prompt throughput: 29.4 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! expectedModCount => 0 prob: 0.3307843703660092 => 0.26318594025980324
INFO 02-28 20:39:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:54 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:39:59 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:04 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:14 llm_engine.py:878] Avg prompt throughput: 22.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:24 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:29 llm_engine.py:878] Avg prompt throughput: 29.3 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:44 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:49 llm_engine.py:878] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:54 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:40:59 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
ACC! lastLink => current prob: 0.26318594025980324 => 0.1442539363090624
INFO 02-28 20:41:04 llm_engine.py:878] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:14 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
NOACC! remove => remove prob: 0.1442539363090624 => 0.1442539363090624
INFO 02-28 20:41:24 llm_engine.py:878] Avg prompt throughput: 26.6 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:39 llm_engine.py:878] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:44 llm_engine.py:878] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:54 llm_engine.py:878] Avg prompt throughput: 22.5 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:41:59 llm_engine.py:878] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:04 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:09 llm_engine.py:878] Avg prompt throughput: 35.2 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:14 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:19 llm_engine.py:878] Avg prompt throughput: 24.1 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:24 llm_engine.py:878] Avg prompt throughput: 28.2 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:29 llm_engine.py:878] Avg prompt throughput: 33.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
71it [1:54:52, 200.52s/it]ACC! modCount => position prob: 0.1442539363090624 => 0.12954805395612123
Example index 70
Example time cost:  10.78 min
ALL examples time cost:  114.88 min
Origin CodeBLEU: 0.4787028451284312
Attacked CodeBLEU: 0.12954805395612123
Greedy_query_times:  199
Ga_query_times:  0
ALL query times:  2631




INFO 02-28 20:42:44 llm_engine.py:878] Avg prompt throughput: 8.6 tokens/s, Avg generation throughput: 43.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:49 llm_engine.py:878] Avg prompt throughput: 12.3 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:42:54 llm_engine.py:878] Avg prompt throughput: 12.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! mergeShards => update prob: 1.0 => 0.9017295359335316
INFO 02-28 20:42:59 llm_engine.py:878] Avg prompt throughput: 18.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:04 llm_engine.py:878] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:09 llm_engine.py:878] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:14 llm_engine.py:878] Avg prompt throughput: 19.4 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:19 llm_engine.py:878] Avg prompt throughput: 11.8 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
72it [1:55:35, 153.06s/it]ACC! request => merge prob: 0.9017295359335316 => 0.1478631136068262
Example index 71
Example time cost:  0.71 min
ALL examples time cost:  115.58 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  2830




INFO 02-28 20:43:24 llm_engine.py:878] Avg prompt throughput: 19.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:29 llm_engine.py:878] Avg prompt throughput: 19.1 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:34 llm_engine.py:878] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:39 llm_engine.py:878] Avg prompt throughput: 10.7 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! allocateHostedConnection => allocate prob: 1.0 => 0.9017295359335316
INFO 02-28 20:43:44 llm_engine.py:878] Avg prompt throughput: 18.8 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:49 llm_engine.py:878] Avg prompt throughput: 13.9 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:54 llm_engine.py:878] Avg prompt throughput: 11.4 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:43:59 llm_engine.py:878] Avg prompt throughput: 19.2 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
73it [1:56:12, 118.43s/it]74it [1:56:14, 83.49s/it] ACC! request => p prob: 0.9017295359335316 => 0.1478631136068262
Example index 72
Example time cost:  0.63 min
ALL examples time cost:  116.21 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  2851




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getBeginIndex => size prob: 0.34643349211829877 => 0.18832906855132966
Example index 73
Example time cost:  0.03 min
ALL examples time cost:  116.24 min
Origin CodeBLEU: 0.34643349211829877
Attacked CodeBLEU: 0.18832906855132966
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  2869




INFO 02-28 20:44:04 llm_engine.py:878] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
ACC! getTerms => filter prob: 1.0 => 0.5951753662100177
INFO 02-28 20:44:09 llm_engine.py:878] Avg prompt throughput: 44.1 tokens/s, Avg generation throughput: 39.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
75it [1:56:24, 61.35s/it]ACC! query => filter prob: 0.5951753662100177 => 0.5916901527087881
Example index 74
Example time cost:  0.16 min
ALL examples time cost:  116.41 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5916901527087881
Greedy_query_times:  16
Ga_query_times:  0
ALL query times:  2876




INFO 02-28 20:44:14 llm_engine.py:878] Avg prompt throughput: 31.6 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
76it [1:56:29, 44.50s/it]ACC! compact => create prob: 1.0 => 0.6290520930089296
Example index 75
Example time cost:  0.09 min
ALL examples time cost:  116.49 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.6290520930089296
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  2892




INFO 02-28 20:44:19 llm_engine.py:878] Avg prompt throughput: 8.7 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:24 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:34 llm_engine.py:878] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:39 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:44 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:54 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:44:59 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:15 llm_engine.py:878] Avg prompt throughput: 35.7 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:35 llm_engine.py:878] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:45:55 llm_engine.py:878] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:15 llm_engine.py:878] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:35 llm_engine.py:878] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:46:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:00 llm_engine.py:878] Avg prompt throughput: 36.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:20 llm_engine.py:878] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:40 llm_engine.py:878] Avg prompt throughput: 40.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! byte0 => blocks prob: 0.6588038158122457 => 0.6181813049243459
INFO 02-28 20:47:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:47:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:00 llm_engine.py:878] Avg prompt throughput: 42.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! decode => shuffle prob: 0.6181813049243459 => 0.5864429152443049
INFO 02-28 20:48:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:20 llm_engine.py:878] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:40 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:48:55 llm_engine.py:878] Avg prompt throughput: 43.4 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:15 llm_engine.py:878] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:30 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:35 llm_engine.py:878] Avg prompt throughput: 35.9 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
ACC! valuesOffset => buffer prob: 0.5864429152443049 => 0.46255704869820735
INFO 02-28 20:49:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:50 llm_engine.py:878] Avg prompt throughput: 42.6 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:49:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:05 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:10 llm_engine.py:878] Avg prompt throughput: 40.8 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:15 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:25 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:30 llm_engine.py:878] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:35 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:40 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:50 llm_engine.py:878] Avg prompt throughput: 36.3 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:50:55 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:00 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:11 llm_engine.py:878] Avg prompt throughput: 35.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
ACC! iterations => update prob: 0.46255704869820735 => 0.43721393645290774
INFO 02-28 20:51:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:26 llm_engine.py:878] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:46 llm_engine.py:878] Avg prompt throughput: 34.2 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:51:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:01 llm_engine.py:878] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:16 llm_engine.py:878] Avg prompt throughput: 42.4 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:36 llm_engine.py:878] Avg prompt throughput: 36.6 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:51 llm_engine.py:878] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:52:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:11 llm_engine.py:878] Avg prompt throughput: 34.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:26 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:41 llm_engine.py:878] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! byte1 => blocks prob: 0.43721393645290774 => 0.410685871769243
INFO 02-28 20:53:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:53:56 llm_engine.py:878] Avg prompt throughput: 43.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:11 llm_engine.py:878] Avg prompt throughput: 43.3 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:26 llm_engine.py:878] Avg prompt throughput: 43.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:41 llm_engine.py:878] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:54:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:01 llm_engine.py:878] Avg prompt throughput: 33.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:11 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:16 llm_engine.py:878] Avg prompt throughput: 34.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:21 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:31 llm_engine.py:878] Avg prompt throughput: 34.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:46 llm_engine.py:878] Avg prompt throughput: 34.4 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:51 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:55:56 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:11 llm_engine.py:878] Avg prompt throughput: 34.3 tokens/s, Avg generation throughput: 42.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:16 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:21 llm_engine.py:878] Avg prompt throughput: 40.7 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! byte2 => value prob: 0.410685871769243 => 0.3821557044427652
INFO 02-28 20:56:26 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:31 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:36 llm_engine.py:878] Avg prompt throughput: 34.6 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:41 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:46 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
ACC! blocks => blocks prob: 0.3821557044427652 => 0.35375558984150424
INFO 02-28 20:56:51 llm_engine.py:878] Avg prompt throughput: 35.0 tokens/s, Avg generation throughput: 42.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:56:56 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:01 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:06 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:11 llm_engine.py:878] Avg prompt throughput: 33.3 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:42 llm_engine.py:878] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:57:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:02 llm_engine.py:878] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
ACC! values => result prob: 0.35375558984150424 => 0.34758623401826677
INFO 02-28 20:58:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:22 llm_engine.py:878] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:52 llm_engine.py:878] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:58:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 19.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:27 llm_engine.py:878] Avg prompt throughput: 36.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 20:59:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:02 llm_engine.py:878] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
ACC! i => x prob: 0.34758623401826677 => 0.25626323214423197
INFO 02-28 21:00:27 llm_engine.py:878] Avg prompt throughput: 34.7 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:52 llm_engine.py:878] Avg prompt throughput: 35.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:00:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:22 llm_engine.py:878] Avg prompt throughput: 33.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
77it [2:13:39, 340.11s/it]ACC! blocksOffset => generate prob: 0.25626323214423197 => 0.25543731075825377
Example index 76
Example time cost:  17.16 min
ALL examples time cost:  133.66 min
Origin CodeBLEU: 0.6588038158122457
Attacked CodeBLEU: 0.25543731075825377
Greedy_query_times:  257
Ga_query_times:  0
ALL query times:  2899




INFO 02-28 21:01:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 5.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:01:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:42 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:47 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:52 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:02:57 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:02 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:07 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:12 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:17 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:22 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
ACC! elements => result prob: 0.526724427390098 => 0.3902364320057222
INFO 02-28 21:03:27 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:37 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:03:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:04:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.7%, CPU KV cache usage: 0.0%
ACC! result => s prob: 0.3902364320057222 => 0.34798264185117267
INFO 02-28 21:05:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
ACC! s => split prob: 0.34798264185117267 => 0.3282472943366572
INFO 02-28 21:05:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:05:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
NOACC! getHumanishName => host prob: 0.3282472943366572 => 0.3326506342252088
INFO 02-28 21:06:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:33 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:38 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 4.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:48 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:53 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:06:58 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:08 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:13 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:18 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.8%, CPU KV cache usage: 0.0%
78it [2:19:33, 344.31s/it]ACC! elseelements => Elements prob: 0.3282472943366572 => 0.3262969275847287
Example index 77
Example time cost:  5.9 min
ALL examples time cost:  139.56 min
Origin CodeBLEU: 0.526724427390098
Attacked CodeBLEU: 0.3262969275847287
Greedy_query_times:  69
Ga_query_times:  0
ALL query times:  3156




INFO 02-28 21:07:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:28 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:33 llm_engine.py:878] Avg prompt throughput: 17.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:38 llm_engine.py:878] Avg prompt throughput: 18.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:43 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:48 llm_engine.py:878] Avg prompt throughput: 13.2 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:07:53 llm_engine.py:878] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
NOACC! request => input prob: 1.0 => 1.0
INFO 02-28 21:07:58 llm_engine.py:878] Avg prompt throughput: 20.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:03 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:08 llm_engine.py:878] Avg prompt throughput: 12.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
79it [2:20:24, 256.38s/it]ACC! describeNotebookInstanceLifecycleConfig => request prob: 1.0 => 0.9017295359335316
Example index 78
Example time cost:  0.85 min
ALL examples time cost:  140.41 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.9017295359335316
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  3225




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 21:08:13 llm_engine.py:878] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
80it [2:20:27, 180.19s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getAccessKeySecret => name prob: 0.27536057822679394 => 0.1621668519367607
Example index 79
Example time cost:  0.04 min
ALL examples time cost:  140.45 min
Origin CodeBLEU: 0.27536057822679394
Attacked CodeBLEU: 0.1621668519367607
Greedy_query_times:  6
Ga_query_times:  0
ALL query times:  3242




INFO 02-28 21:08:18 llm_engine.py:878] Avg prompt throughput: 23.7 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:23 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:28 llm_engine.py:878] Avg prompt throughput: 19.3 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:33 llm_engine.py:878] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:38 llm_engine.py:878] Avg prompt throughput: 13.2 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:43 llm_engine.py:878] Avg prompt throughput: 20.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! request => resource prob: 1.0 => 0.4522584394394781
INFO 02-28 21:08:48 llm_engine.py:878] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
81it [2:21:05, 137.50s/it]ACC! createVpnConnection => connect prob: 0.4522584394394781 => 0.24558772609968524
Example index 80
Example time cost:  0.63 min
ALL examples time cost:  141.08 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.24558772609968524
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  3248




INFO 02-28 21:08:53 llm_engine.py:878] Avg prompt throughput: 16.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:08:58 llm_engine.py:878] Avg prompt throughput: 10.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:03 llm_engine.py:878] Avg prompt throughput: 15.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:08 llm_engine.py:878] Avg prompt throughput: 11.9 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! describeVoices => request prob: 1.0 => 0.9017295359335316
INFO 02-28 21:09:13 llm_engine.py:878] Avg prompt throughput: 18.9 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:18 llm_engine.py:878] Avg prompt throughput: 19.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:23 llm_engine.py:878] Avg prompt throughput: 14.5 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
82it [2:21:40, 106.74s/it]ACC! request => parent prob: 0.9017295359335316 => 0.1478631136068262
Example index 81
Example time cost:  0.58 min
ALL examples time cost:  141.67 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  3268




INFO 02-28 21:09:28 llm_engine.py:878] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:33 llm_engine.py:878] Avg prompt throughput: 10.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:38 llm_engine.py:878] Avg prompt throughput: 15.7 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:43 llm_engine.py:878] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:48 llm_engine.py:878] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:53 llm_engine.py:878] Avg prompt throughput: 19.2 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:09:58 llm_engine.py:878] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! request => execute prob: 1.0 => 0.1495668749796641
INFO 02-28 21:10:03 llm_engine.py:878] Avg prompt throughput: 23.4 tokens/s, Avg generation throughput: 43.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
83it [2:22:17, 86.03s/it] ACC! listMonitoringExecutions => lists prob: 0.1495668749796641 => 0.12338394694015953
Example index 82
Example time cost:  0.63 min
ALL examples time cost:  142.3 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.12338394694015953
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  3285




INFO 02-28 21:10:08 llm_engine.py:878] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! vaultName => account prob: 1.0 => 0.5407607951517033
INFO 02-28 21:10:13 llm_engine.py:878] Avg prompt throughput: 48.7 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
84it [2:22:29, 63.66s/it]ACC! jobId => identifier prob: 0.5407607951517033 => 0.3665425960232924
Example index 83
Example time cost:  0.19 min
ALL examples time cost:  142.49 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.3665425960232924
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  3306




INFO 02-28 21:10:18 llm_engine.py:878] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! getEscherRecord => record prob: 1.0 => 0.5814150209792306
INFO 02-28 21:10:23 llm_engine.py:878] Avg prompt throughput: 45.7 tokens/s, Avg generation throughput: 41.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
85it [2:22:39, 47.63s/it]ACC! index => get prob: 0.5814150209792306 => 0.5606803453800826
Example index 84
Example time cost:  0.17 min
ALL examples time cost:  142.66 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5606803453800826
Greedy_query_times:  16
Ga_query_times:  0
ALL query times:  3323




INFO 02-28 21:10:28 llm_engine.py:878] Avg prompt throughput: 34.4 tokens/s, Avg generation throughput: 42.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:10:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:10:39 llm_engine.py:878] Avg prompt throughput: 20.3 tokens/s, Avg generation throughput: 43.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:10:44 llm_engine.py:878] Avg prompt throughput: 10.6 tokens/s, Avg generation throughput: 43.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! getApis => get prob: 1.0 => 0.9017295359335316
INFO 02-28 21:10:49 llm_engine.py:878] Avg prompt throughput: 14.6 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:10:54 llm_engine.py:878] Avg prompt throughput: 22.6 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:10:59 llm_engine.py:878] Avg prompt throughput: 22.6 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
86it [2:23:14, 43.72s/it]ACC! request => argument prob: 0.9017295359335316 => 0.1478631136068262
Example index 85
Example time cost:  0.58 min
ALL examples time cost:  143.23 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  3339




INFO 02-28 21:11:04 llm_engine.py:878] Avg prompt throughput: 16.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:11:09 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:11:14 llm_engine.py:878] Avg prompt throughput: 16.4 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! deleteSmsChannel => execute prob: 1.0 => 0.9017295359335316
INFO 02-28 21:11:19 llm_engine.py:878] Avg prompt throughput: 19.8 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:11:24 llm_engine.py:878] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:11:29 llm_engine.py:878] Avg prompt throughput: 23.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:11:34 llm_engine.py:878] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
87it [2:23:50, 41.50s/it]ACC! request => request prob: 0.9017295359335316 => 0.11101779823773752
Example index 86
Example time cost:  0.61 min
ALL examples time cost:  143.84 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  3359




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 21:11:39 llm_engine.py:878] Avg prompt throughput: 16.7 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
88it [2:23:54, 30.36s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getTrackingRefUpdate => copy prob: 0.75 => 0.221942851816312
Example index 87
Example time cost:  0.07 min
ALL examples time cost:  143.91 min
Origin CodeBLEU: 0.75
Attacked CodeBLEU: 0.221942851816312
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  3379




INFO 02-28 21:11:44 llm_engine.py:878] Avg prompt throughput: 32.7 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! print => b prob: 1.0 => 0.5146861490546798
INFO 02-28 21:11:49 llm_engine.py:878] Avg prompt throughput: 50.3 tokens/s, Avg generation throughput: 38.6 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
89it [2:24:04, 24.12s/it]ACC! b => println prob: 0.5146861490546798 => 0.33135281572134645
Example index 88
Example time cost:  0.16 min
ALL examples time cost:  144.07 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.33135281572134645
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  3386




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 21:11:54 llm_engine.py:878] Avg prompt throughput: 48.7 tokens/s, Avg generation throughput: 38.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
90it [2:24:07, 17.82s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! getChild => last prob: 0.3318059992830803 => 0.15800973376133104
Example index 89
Example time cost:  0.05 min
ALL examples time cost:  144.12 min
Origin CodeBLEU: 0.3318059992830803
Attacked CodeBLEU: 0.15800973376133104
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  3405




INFO 02-28 21:11:59 llm_engine.py:878] Avg prompt throughput: 34.4 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! index => 0 prob: 1.0 => 0.49808168764589733
INFO 02-28 21:12:04 llm_engine.py:878] Avg prompt throughput: 44.2 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
91it [2:24:18, 15.85s/it]ACC! workdirTreeIndex => indexed prob: 0.49808168764589733 => 0.48164543897478307
Example index 90
Example time cost:  0.19 min
ALL examples time cost:  144.31 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.48164543897478307
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  3412




INFO 02-28 21:12:09 llm_engine.py:878] Avg prompt throughput: 45.0 tokens/s, Avg generation throughput: 39.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
ACC! field_1_formatFlags => in prob: 1.0 => 0.5189150209792306
INFO 02-28 21:12:14 llm_engine.py:878] Avg prompt throughput: 44.7 tokens/s, Avg generation throughput: 39.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
92it [2:24:27, 13.69s/it]93it [2:24:28,  9.95s/it]ACC! in => in prob: 0.5189150209792306 => 0.43997877230811644
Example index 91
Example time cost:  0.14 min
ALL examples time cost:  144.45 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.43997877230811644
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  3431




Example index 92
Example time cost:  0.02 min
ALL examples time cost:  144.48 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 1.0
Greedy_query_times:  1
Ga_query_times:  0
ALL query times:  3448




INFO 02-28 21:12:19 llm_engine.py:878] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:12:24 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 3.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:12:29 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:12:34 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:12:39 llm_engine.py:878] Avg prompt throughput: 13.1 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:12:44 llm_engine.py:878] Avg prompt throughput: 18.2 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! describeTransitGatewayVpcAttachments => list prob: 1.0 => 0.9017295359335316
INFO 02-28 21:12:49 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:12:54 llm_engine.py:878] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:12:59 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:04 llm_engine.py:878] Avg prompt throughput: 14.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:09 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
94it [2:25:23, 23.38s/it]ACC! request => instruction prob: 0.9017295359335316 => 0.11101779823773752
Example index 93
Example time cost:  0.91 min
ALL examples time cost:  145.39 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  3449




INFO 02-28 21:13:14 llm_engine.py:878] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:19 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:24 llm_engine.py:878] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:29 llm_engine.py:878] Avg prompt throughput: 13.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! putVoiceConnectorStreamingConfiguration => execute prob: 1.0 => 0.9017295359335316
INFO 02-28 21:13:34 llm_engine.py:878] Avg prompt throughput: 13.1 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:39 llm_engine.py:878] Avg prompt throughput: 25.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:44 llm_engine.py:878] Avg prompt throughput: 16.7 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:13:49 llm_engine.py:878] Avg prompt throughput: 15.8 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
95it [2:26:06, 29.32s/it]ACC! request => execute prob: 0.9017295359335316 => 0.11101779823773752
Example index 94
Example time cost:  0.72 min
ALL examples time cost:  146.11 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  3467




INFO 02-28 21:13:54 llm_engine.py:878] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
NOACC! getOrdRange => get prob: 0.14175320303732375 => 0.14175320303732375
INFO 02-28 21:13:59 llm_engine.py:878] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:04 llm_engine.py:878] Avg prompt throughput: 46.5 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
96it [2:26:18, 24.20s/it]NOACC! dim => get prob: 0.14175320303732375 => 0.14175320303732375
Example index 95
Example time cost:  0.2 min
ALL examples time cost:  146.31 min
Origin CodeBLEU: 0.14175320303732375
Attacked CodeBLEU: 0.14175320303732375
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  3484




INFO 02-28 21:14:09 llm_engine.py:878] Avg prompt throughput: 32.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:14 llm_engine.py:878] Avg prompt throughput: 32.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:19 llm_engine.py:878] Avg prompt throughput: 23.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:24 llm_engine.py:878] Avg prompt throughput: 22.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:29 llm_engine.py:878] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:34 llm_engine.py:878] Avg prompt throughput: 33.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:39 llm_engine.py:878] Avg prompt throughput: 29.5 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! symbol => input prob: 0.5056540164540886 => 0.41460211970838834
INFO 02-28 21:14:44 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:14:49 llm_engine.py:878] Avg prompt throughput: 25.3 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
97it [2:27:05, 31.13s/it]ACC! toString => generate prob: 0.41460211970838834 => 0.37860940123794445
Example index 96
Example time cost:  0.79 min
ALL examples time cost:  147.1 min
Origin CodeBLEU: 0.5056540164540886
Attacked CodeBLEU: 0.37860940123794445
Greedy_query_times:  20
Ga_query_times:  0
ALL query times:  3503




WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
INFO 02-28 21:14:54 llm_engine.py:878] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
98it [2:27:08, 22.64s/it]WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
WARNING: There is no reference data-flows extracted from the whole corpus, and the data-flow match score degenerates to 0. Please consider ignoring this score.
ACC! peek => pop prob: 0.75 => 0.3889234674480551
Example index 97
Example time cost:  0.05 min
ALL examples time cost:  147.15 min
Origin CodeBLEU: 0.75
Attacked CodeBLEU: 0.3889234674480551
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  3523




INFO 02-28 21:14:59 llm_engine.py:878] Avg prompt throughput: 19.0 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:04 llm_engine.py:878] Avg prompt throughput: 16.8 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:09 llm_engine.py:878] Avg prompt throughput: 16.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! createWorkspaces => create prob: 1.0 => 0.9017295359335316
INFO 02-28 21:15:14 llm_engine.py:878] Avg prompt throughput: 19.3 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:19 llm_engine.py:878] Avg prompt throughput: 21.6 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:24 llm_engine.py:878] Avg prompt throughput: 17.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:29 llm_engine.py:878] Avg prompt throughput: 15.9 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
99it [2:27:45, 26.77s/it]ACC! request => request prob: 0.9017295359335316 => 0.1478631136068262
Example index 98
Example time cost:  0.61 min
ALL examples time cost:  147.75 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  3530




INFO 02-28 21:15:34 llm_engine.py:878] Avg prompt throughput: 30.1 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%
100it [2:27:48, 19.64s/it]ACC! clone => get prob: 0.10241843642840687 => 0.051017307096485484
Example index 99
Example time cost:  0.05 min
ALL examples time cost:  147.8 min
Origin CodeBLEU: 0.10241843642840687
Attacked CodeBLEU: 0.051017307096485484
Greedy_query_times:  7
Ga_query_times:  0
ALL query times:  3551




INFO 02-28 21:15:39 llm_engine.py:878] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:44 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:49 llm_engine.py:878] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:15:54 llm_engine.py:878] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! describeRepositories => list prob: 1.0 => 0.9017295359335316
INFO 02-28 21:15:59 llm_engine.py:878] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:04 llm_engine.py:878] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:09 llm_engine.py:878] Avg prompt throughput: 13.5 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:14 llm_engine.py:878] Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
101it [2:28:27, 25.67s/it]ACC! request => call prob: 0.9017295359335316 => 0.11101779823773752
Example index 100
Example time cost:  0.66 min
ALL examples time cost:  148.47 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  18
Ga_query_times:  0
ALL query times:  3558




INFO 02-28 21:16:19 llm_engine.py:878] Avg prompt throughput: 25.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:24 llm_engine.py:878] Avg prompt throughput: 20.9 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:29 llm_engine.py:878] Avg prompt throughput: 35.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:34 llm_engine.py:878] Avg prompt throughput: 45.4 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! initialCapacity => 0 prob: 0.7133376593197106 => 0.29886626527205085
INFO 02-28 21:16:39 llm_engine.py:878] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:44 llm_engine.py:878] Avg prompt throughput: 43.5 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:49 llm_engine.py:878] Avg prompt throughput: 50.4 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! mKeys => capacity prob: 0.29886626527205085 => 0.25474861821322736
INFO 02-28 21:16:54 llm_engine.py:878] Avg prompt throughput: 32.1 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:16:59 llm_engine.py:878] Avg prompt throughput: 30.6 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:17:04 llm_engine.py:878] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:17:09 llm_engine.py:878] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
NOACC! mSize => N prob: 0.25474861821322736 => 0.25474861821322736
INFO 02-28 21:17:14 llm_engine.py:878] Avg prompt throughput: 48.2 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:17:19 llm_engine.py:878] Avg prompt throughput: 46.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:17:25 llm_engine.py:878] Avg prompt throughput: 45.4 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
102it [2:29:40, 39.77s/it]NOACC! mValues => Values prob: 0.25474861821322736 => 0.25474861821322736
Example index 101
Example time cost:  1.21 min
ALL examples time cost:  149.68 min
Origin CodeBLEU: 0.7133376593197106
Attacked CodeBLEU: 0.25474861821322736
Greedy_query_times:  64
Ga_query_times:  0
ALL query times:  3576




INFO 02-28 21:17:30 llm_engine.py:878] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! create => filter prob: 1.0 => 0.7316620636843809
INFO 02-28 21:17:35 llm_engine.py:878] Avg prompt throughput: 41.6 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:17:40 llm_engine.py:878] Avg prompt throughput: 49.8 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
103it [2:29:53, 31.69s/it]NOACC! input => input prob: 0.7316620636843809 => 0.7316620636843809
Example index 102
Example time cost:  0.21 min
ALL examples time cost:  149.89 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.7316620636843809
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  3640




INFO 02-28 21:17:45 llm_engine.py:878] Avg prompt throughput: 20.3 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:17:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:17:55 llm_engine.py:878] Avg prompt throughput: 12.7 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:00 llm_engine.py:878] Avg prompt throughput: 21.1 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:05 llm_engine.py:878] Avg prompt throughput: 15.5 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:10 llm_engine.py:878] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:15 llm_engine.py:878] Avg prompt throughput: 21.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! request => create prob: 1.0 => 0.8330700172095619
INFO 02-28 21:18:20 llm_engine.py:878] Avg prompt throughput: 15.6 tokens/s, Avg generation throughput: 41.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:25 llm_engine.py:878] Avg prompt throughput: 11.5 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
104it [2:30:40, 36.37s/it]ACC! createDistributionWithTags => run prob: 0.8330700172095619 => 0.7953006008130087
Example index 103
Example time cost:  0.79 min
ALL examples time cost:  150.68 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.7953006008130087
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  3657




INFO 02-28 21:18:30 llm_engine.py:878] Avg prompt throughput: 17.2 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:35 llm_engine.py:878] Avg prompt throughput: 30.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! fileName => file prob: 0.77354317588984 => 0.4871728128733858
INFO 02-28 21:18:40 llm_engine.py:878] Avg prompt throughput: 32.7 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
105it [2:30:55, 29.92s/it]ACC! mode => encoding prob: 0.4871728128733858 => 0.2466343812595215
Example index 104
Example time cost:  0.25 min
ALL examples time cost:  150.93 min
Origin CodeBLEU: 0.77354317588984
Attacked CodeBLEU: 0.2466343812595215
Greedy_query_times:  16
Ga_query_times:  0
ALL query times:  3678




INFO 02-28 21:18:45 llm_engine.py:878] Avg prompt throughput: 29.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:50 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:18:55 llm_engine.py:878] Avg prompt throughput: 16.3 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:00 llm_engine.py:878] Avg prompt throughput: 11.2 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
ACC! deleteWorkspaceImage => begin prob: 1.0 => 0.9017295359335316
INFO 02-28 21:19:05 llm_engine.py:878] Avg prompt throughput: 17.1 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:10 llm_engine.py:878] Avg prompt throughput: 21.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:15 llm_engine.py:878] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:20 llm_engine.py:878] Avg prompt throughput: 17.8 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
106it [2:31:35, 32.91s/it]ACC! request => req prob: 0.9017295359335316 => 0.11101779823773752
Example index 105
Example time cost:  0.66 min
ALL examples time cost:  151.59 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.11101779823773752
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  3694




INFO 02-28 21:19:25 llm_engine.py:878] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:30 llm_engine.py:878] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
NOACC! toHex => escape prob: 0.40612413723812546 => 0.40612413723812546
INFO 02-28 21:19:35 llm_engine.py:878] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:40 llm_engine.py:878] Avg prompt throughput: 45.0 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
NOACC! value => length prob: 0.40612413723812546 => 0.40612413723812546
INFO 02-28 21:19:45 llm_engine.py:878] Avg prompt throughput: 35.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:50 llm_engine.py:878] Avg prompt throughput: 40.1 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:19:55 llm_engine.py:878] Avg prompt throughput: 42.0 tokens/s, Avg generation throughput: 39.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:00 llm_engine.py:878] Avg prompt throughput: 33.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
107it [2:32:14, 34.69s/it]ACC! sb => value prob: 0.40612413723812546 => 0.34362413723812546
Example index 106
Example time cost:  0.65 min
ALL examples time cost:  152.24 min
Origin CodeBLEU: 0.40612413723812546
Attacked CodeBLEU: 0.34362413723812546
Greedy_query_times:  37
Ga_query_times:  0
ALL query times:  3715




INFO 02-28 21:20:05 llm_engine.py:878] Avg prompt throughput: 24.9 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:10 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:15 llm_engine.py:878] Avg prompt throughput: 16.6 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:20 llm_engine.py:878] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:25 llm_engine.py:878] Avg prompt throughput: 10.4 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:30 llm_engine.py:878] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
ACC! request => execute prob: 1.0 => 0.19827359233036074
INFO 02-28 21:20:35 llm_engine.py:878] Avg prompt throughput: 33.8 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
108it [2:32:48, 34.68s/it]ACC! updateDistribution => update prob: 0.19827359233036074 => 0.1478631136068262
Example index 107
Example time cost:  0.58 min
ALL examples time cost:  152.82 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  3752




INFO 02-28 21:20:40 llm_engine.py:878] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 40.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:45 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:50 llm_engine.py:878] Avg prompt throughput: 42.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:20:55 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:00 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:05 llm_engine.py:878] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
ACC! getColor => rgb prob: 0.5052540883266547 => 0.4247934438486927
INFO 02-28 21:21:10 llm_engine.py:878] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:15 llm_engine.py:878] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:20 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:25 llm_engine.py:878] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:30 llm_engine.py:878] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:35 llm_engine.py:878] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:40 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:45 llm_engine.py:878] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! b => index prob: 0.4247934438486927 => 0.3873625717823854
INFO 02-28 21:21:50 llm_engine.py:878] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:21:55 llm_engine.py:878] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:00 llm_engine.py:878] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:05 llm_engine.py:878] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:10 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:15 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
109it [2:34:29, 54.38s/it]ACC! index => rgb prob: 0.3873625717823854 => 0.3619420557085431
Example index 108
Example time cost:  1.67 min
ALL examples time cost:  154.49 min
Origin CodeBLEU: 0.5052540883266547
Attacked CodeBLEU: 0.3619420557085431
Greedy_query_times:  49
Ga_query_times:  0
ALL query times:  3773




INFO 02-28 21:22:20 llm_engine.py:878] Avg prompt throughput: 19.8 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:25 llm_engine.py:878] Avg prompt throughput: 19.2 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:30 llm_engine.py:878] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! operands => eval prob: 0.8776644327756606 => 0.7359038584411166
INFO 02-28 21:22:35 llm_engine.py:878] Avg prompt throughput: 36.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! evaluate => apply prob: 0.7359038584411166 => 0.7179814659135655
INFO 02-28 21:22:40 llm_engine.py:878] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:45 llm_engine.py:878] Avg prompt throughput: 44.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! srcRow => eval prob: 0.7179814659135655 => 0.5975502435332617
INFO 02-28 21:22:50 llm_engine.py:878] Avg prompt throughput: 37.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:22:55 llm_engine.py:878] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 39.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:23:00 llm_engine.py:878] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
110it [2:35:16, 52.22s/it]ACC! srcCol => eval prob: 0.5975502435332617 => 0.47911860576907594
Example index 109
Example time cost:  0.79 min
ALL examples time cost:  155.27 min
Origin CodeBLEU: 0.8776644327756606
Attacked CodeBLEU: 0.47911860576907594
Greedy_query_times:  49
Ga_query_times:  0
ALL query times:  3822




INFO 02-28 21:23:05 llm_engine.py:878] Avg prompt throughput: 35.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:23:10 llm_engine.py:878] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
ACC! serialize => encode prob: 1.0 => 0.4646861490546798
INFO 02-28 21:23:15 llm_engine.py:878] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:23:20 llm_engine.py:878] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
111it [2:35:37, 42.94s/it]NOACC! out => output prob: 0.4646861490546798 => 0.4646861490546798
Example index 110
Example time cost:  0.35 min
ALL examples time cost:  155.63 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.4646861490546798
Greedy_query_times:  17
Ga_query_times:  0
ALL query times:  3871




INFO 02-28 21:23:25 llm_engine.py:878] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:23:30 llm_engine.py:878] Avg prompt throughput: 35.3 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
112it [2:35:45, 32.41s/it]ACC! describeDBEngineVersions => request prob: 1.0 => 0.4323804908695723
Example index 111
Example time cost:  0.13 min
ALL examples time cost:  155.76 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.4323804908695723
Greedy_query_times:  9
Ga_query_times:  0
ALL query times:  3888




INFO 02-28 21:23:35 llm_engine.py:878] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%
INFO 02-28 21:23:40 llm_engine.py:878] Avg prompt throughput: 32.7 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:23:45 llm_engine.py:878] Avg prompt throughput: 46.1 tokens/s, Avg generation throughput: 39.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! _fontIndex => character prob: 1.0 => 0.7910267532097613
INFO 02-28 21:23:50 llm_engine.py:878] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
ACC! character => characteristic prob: 0.7910267532097613 => 0.5469502039865674
INFO 02-28 21:23:55 llm_engine.py:878] Avg prompt throughput: 47.5 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! fontIndex => font prob: 0.5469502039865674 => 0.4915425960232924
INFO 02-28 21:24:00 llm_engine.py:878] Avg prompt throughput: 48.8 tokens/s, Avg generation throughput: 42.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
113it [2:36:16, 31.96s/it]ACC! _character => rune prob: 0.4915425960232924 => 0.41040224514609946
Example index 112
Example time cost:  0.52 min
ALL examples time cost:  156.28 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.41040224514609946
Greedy_query_times:  46
Ga_query_times:  0
ALL query times:  3897




INFO 02-28 21:24:05 llm_engine.py:878] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:10 llm_engine.py:878] Avg prompt throughput: 48.6 tokens/s, Avg generation throughput: 42.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:15 llm_engine.py:878] Avg prompt throughput: 49.5 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:20 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 43.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:26 llm_engine.py:878] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:31 llm_engine.py:878] Avg prompt throughput: 47.7 tokens/s, Avg generation throughput: 42.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:36 llm_engine.py:878] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:41 llm_engine.py:878] Avg prompt throughput: 39.6 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:46 llm_engine.py:878] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 42.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:51 llm_engine.py:878] Avg prompt throughput: 35.8 tokens/s, Avg generation throughput: 42.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:24:56 llm_engine.py:878] Avg prompt throughput: 33.8 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:01 llm_engine.py:878] Avg prompt throughput: 32.8 tokens/s, Avg generation throughput: 42.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:06 llm_engine.py:878] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 42.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:11 llm_engine.py:878] Avg prompt throughput: 30.3 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:16 llm_engine.py:878] Avg prompt throughput: 30.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:21 llm_engine.py:878] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:26 llm_engine.py:878] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:31 llm_engine.py:878] Avg prompt throughput: 32.7 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
ACC! result => data prob: 0.8212147779843257 => 0.7615827862549478
INFO 02-28 21:25:36 llm_engine.py:878] Avg prompt throughput: 33.1 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:41 llm_engine.py:878] Avg prompt throughput: 33.5 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:46 llm_engine.py:878] Avg prompt throughput: 34.5 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:51 llm_engine.py:878] Avg prompt throughput: 35.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:25:56 llm_engine.py:878] Avg prompt throughput: 36.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:01 llm_engine.py:878] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:06 llm_engine.py:878] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:11 llm_engine.py:878] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! offset => off prob: 0.7615827862549478 => 0.4638946547351323
INFO 02-28 21:26:16 llm_engine.py:878] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:21 llm_engine.py:878] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:26 llm_engine.py:878] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:31 llm_engine.py:878] Avg prompt throughput: 42.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:36 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:41 llm_engine.py:878] Avg prompt throughput: 22.6 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.5%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:46 llm_engine.py:878] Avg prompt throughput: 22.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:51 llm_engine.py:878] Avg prompt throughput: 22.9 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:26:56 llm_engine.py:878] Avg prompt throughput: 23.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:01 llm_engine.py:878] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:06 llm_engine.py:878] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:11 llm_engine.py:878] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:16 llm_engine.py:878] Avg prompt throughput: 25.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:21 llm_engine.py:878] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! end => off prob: 0.4638946547351323 => 0.3421438244647177
INFO 02-28 21:27:26 llm_engine.py:878] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:31 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:36 llm_engine.py:878] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:41 llm_engine.py:878] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:46 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:51 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:27:56 llm_engine.py:878] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:01 llm_engine.py:878] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:06 llm_engine.py:878] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:11 llm_engine.py:878] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:16 llm_engine.py:878] Avg prompt throughput: 27.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:21 llm_engine.py:878] Avg prompt throughput: 27.6 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:26 llm_engine.py:878] Avg prompt throughput: 27.6 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:31 llm_engine.py:878] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:36 llm_engine.py:878] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
ACC! resultIndex => n prob: 0.3421438244647177 => 0.287888094649788
INFO 02-28 21:28:41 llm_engine.py:878] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:46 llm_engine.py:878] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:51 llm_engine.py:878] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:28:56 llm_engine.py:878] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! chars => input prob: 0.287888094649788 => 0.2851787762783522
INFO 02-28 21:29:01 llm_engine.py:878] Avg prompt throughput: 23.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:06 llm_engine.py:878] Avg prompt throughput: 22.4 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:11 llm_engine.py:878] Avg prompt throughput: 42.7 tokens/s, Avg generation throughput: 40.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:16 llm_engine.py:878] Avg prompt throughput: 41.6 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:21 llm_engine.py:878] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:26 llm_engine.py:878] Avg prompt throughput: 35.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:31 llm_engine.py:878] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:36 llm_engine.py:878] Avg prompt throughput: 32.9 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:41 llm_engine.py:878] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:46 llm_engine.py:878] Avg prompt throughput: 29.5 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:51 llm_engine.py:878] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:29:56 llm_engine.py:878] Avg prompt throughput: 27.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:01 llm_engine.py:878] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:06 llm_engine.py:878] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:11 llm_engine.py:878] Avg prompt throughput: 23.7 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
ACC! i => data prob: 0.2851787762783522 => 0.22880717704690542
INFO 02-28 21:30:16 llm_engine.py:878] Avg prompt throughput: 22.7 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:22 llm_engine.py:878] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:27 llm_engine.py:878] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:32 llm_engine.py:878] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:37 llm_engine.py:878] Avg prompt throughput: 36.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:42 llm_engine.py:878] Avg prompt throughput: 33.9 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:47 llm_engine.py:878] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:52 llm_engine.py:878] Avg prompt throughput: 30.7 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:30:57 llm_engine.py:878] Avg prompt throughput: 29.7 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:02 llm_engine.py:878] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:07 llm_engine.py:878] Avg prompt throughput: 27.2 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:12 llm_engine.py:878] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:17 llm_engine.py:878] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:22 llm_engine.py:878] Avg prompt throughput: 23.8 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:27 llm_engine.py:878] Avg prompt throughput: 22.8 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
ACC! ch => data prob: 0.22880717704690542 => 0.22318110920607123
INFO 02-28 21:31:32 llm_engine.py:878] Avg prompt throughput: 43.4 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:37 llm_engine.py:878] Avg prompt throughput: 35.1 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:42 llm_engine.py:878] Avg prompt throughput: 28.8 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%
NOACC! toBigEndianUtf16Bytes => range prob: 0.22318110920607123 => 0.22318110920607123
INFO 02-28 21:31:47 llm_engine.py:878] Avg prompt throughput: 27.2 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:52 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:31:57 llm_engine.py:878] Avg prompt throughput: 25.3 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:02 llm_engine.py:878] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 40.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:07 llm_engine.py:878] Avg prompt throughput: 23.0 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:12 llm_engine.py:878] Avg prompt throughput: 22.6 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.4%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:17 llm_engine.py:878] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:22 llm_engine.py:878] Avg prompt throughput: 39.3 tokens/s, Avg generation throughput: 40.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
114it [2:44:39, 173.33s/it]ACC! length => data prob: 0.22318110920607123 => 0.14074704581948827
Example index 113
Example time cost:  8.39 min
ALL examples time cost:  164.66 min
Origin CodeBLEU: 0.8212147779843257
Attacked CodeBLEU: 0.14074704581948827
Greedy_query_times:  204
Ga_query_times:  0
ALL query times:  3943




INFO 02-28 21:32:27 llm_engine.py:878] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 40.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:32 llm_engine.py:878] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:37 llm_engine.py:878] Avg prompt throughput: 10.8 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:42 llm_engine.py:878] Avg prompt throughput: 9.9 tokens/s, Avg generation throughput: 41.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
ACC! uploadArchive => create prob: 1.0 => 0.9017295359335316
INFO 02-28 21:32:47 llm_engine.py:878] Avg prompt throughput: 15.2 tokens/s, Avg generation throughput: 41.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:52 llm_engine.py:878] Avg prompt throughput: 17.8 tokens/s, Avg generation throughput: 40.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
INFO 02-28 21:32:57 llm_engine.py:878] Avg prompt throughput: 16.2 tokens/s, Avg generation throughput: 41.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%
INFO 02-28 21:33:02 llm_engine.py:878] Avg prompt throughput: 17.8 tokens/s, Avg generation throughput: 40.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%
115it [2:45:18, 133.00s/it]ACC! request => parent prob: 0.9017295359335316 => 0.1478631136068262
Example index 114
Example time cost:  0.65 min
ALL examples time cost:  165.31 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.1478631136068262
Greedy_query_times:  19
Ga_query_times:  0
ALL query times:  4147




INFO 02-28 21:33:07 llm_engine.py:878] Avg prompt throughput: 21.4 tokens/s, Avg generation throughput: 41.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%
INFO 02-28 21:33:12 llm_engine.py:878] Avg prompt throughput: 33.4 tokens/s, Avg generation throughput: 40.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
ACC! getHiddenTokensToLeft => range prob: 1.0 => 0.5951753662100177
INFO 02-28 21:33:17 llm_engine.py:878] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%
116it [2:45:33, 97.54s/it] ACC! tokenIndex => tail prob: 0.5951753662100177 => 0.5414303377478471
Example index 115
Example time cost:  0.25 min
ALL examples time cost:  165.56 min
Origin CodeBLEU: 1.0
Attacked CodeBLEU: 0.5414303377478471
Greedy_query_times:  21
Ga_query_times:  0
ALL query times:  4166




INFO 02-28 21:33:22 llm_engine.py:878] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 40.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.2%, CPU KV cache usage: 0.0%
INFO 02-28 21:33:27 llm_engine.py:878] Avg prompt throughput: 32.8 tokens/s, Avg generation throughput: 39.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 2.0%, CPU KV cache usage: 0.0%
INFO 02-28 21:33:32 llm_engine.py:878] Avg prompt throughput: 48.8 tokens/s, Avg generation throughput: 40.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%
