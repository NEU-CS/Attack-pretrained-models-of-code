INFO 02-28 17:17:42 llm_engine.py:72] Initializing an LLM engine with config: model='deepseek-ai/deepseek-coder-6.7b-base', tokenizer='deepseek-ai/deepseek-coder-6.7b-base', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, seed=0)
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
INFO 02-28 17:17:45 weight_utils.py:164] Using model weights format ['*.bin']
